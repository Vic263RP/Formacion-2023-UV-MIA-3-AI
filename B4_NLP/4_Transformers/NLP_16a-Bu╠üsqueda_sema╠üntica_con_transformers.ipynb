{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iLfnVvXG6IV4"
      },
      "source": [
        "# Búsqueda semántica de texto\n",
        "En este notebook vamos a implementar un buscador semántico de textos similares mediante un modelo *Transformer* usando el pipeline de extracción de características de Hugging Face (https://huggingface.co/docs/transformers/v4.29.0/en/main_classes/pipelines#transformers.FeatureExtractionPipeline). \\\n",
        "Vamos a usar el conjunto de noticias del dataset Lee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN6c7ojg6IWC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lee_data_file = 'lee_background.cor'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Leemos todas las noticias\n",
        "#Al usar transformers podemos obviar el pre-procesado del texto\n",
        "with open(lee_data_file) as f:\n",
        "    docs = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhyRUBrN6IWD",
        "outputId": "f55b5cf4-c6fc-459d-e865-18964a7a141c"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "Txq4RD2W6IWD",
        "outputId": "9d2cd921-ebd7-4ae7-8694-8d7baf3d71ac"
      },
      "outputs": [],
      "source": [
        "display(docs[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XYhH5iKDab-A"
      },
      "source": [
        "Usamos el embedding del token `[CLS]`a la salida del modelo BERT en inferencia para extraer los vectores de documentos del corpus. Se puede probar con la `pooler_output`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsmn-xMyab-A",
        "outputId": "0417bf1c-d88e-45c8-9a36-b337db1eaf1a"
      },
      "outputs": [],
      "source": [
        "modelo = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def encode(doc):\n",
        "  input = tokenizer(doc, truncation=True, return_tensors=\"pt\")\n",
        "  output = modelo(**input)\n",
        "\n",
        "  return output.last_hidden_state[0,0,:].detach().numpy() #salida [CLS]\n",
        "  #return output.pooler_output.detach().numpy().ravel() #salida 'pooler_output'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_0tqgG7fQWW"
      },
      "outputs": [],
      "source": [
        "output = encode(docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av2vPPnnab-B",
        "outputId": "bd55b3f4-3dc1-49d6-8039-8a0806ff5947"
      },
      "outputs": [],
      "source": [
        "output.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ojmqxM2eab-B"
      },
      "source": [
        "Devuelve una lista de tensores (por cada documento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkbcNG1a6IWD"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "doc_embeddings=np.stack([encode(doc) for doc in tqdm(docs)]) #usamos el vector del token [CLS] como embedding de cada doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC_URDOZab-C",
        "outputId": "747e18e3-5543-4e6e-e155-d4c337a65f61"
      },
      "outputs": [],
      "source": [
        "doc_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "También se podría haber usado el *pipeline* de extracción de características para extraer el embeddings `[CLS]` de cada texto, pero con la sobrecarga de extraer todos los embeddings de todas las capas internas del transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extractor = pipeline(model=\"bert-base-uncased\", task=\"feature-extraction\")\n",
        "result = extractor(docs, \n",
        "    tokenize_kwargs={'padding':True,'truncation':True,'max_length':512},\n",
        "    return_tensors=True)\n",
        "\n",
        "doc_embeddings=np.stack([l[0,0,:].numpy() for l in tqdm(result)])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fGsbCBBz75ub"
      },
      "source": [
        "Los embeddings generados para cada documento son los que usaremos para calcular la similitud entre documentos (con la distancia coseno). Es lo que se conoce como técnica *Bi-encoder*:  \n",
        ">A Bi-Encoder Sentence Transformer model takes in one text at a time as input and outputs a fixed dimension embedding vector as the output. We can then compare any two documents by computing the cosine similarity between the embeddings of those two documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EawwkrF6IWF",
        "outputId": "75776114-1e6a-4def-f09c-13b1c65acfcb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#Vemos la similitud de todos los documentos con todos\n",
        "sims = cosine_similarity(doc_embeddings, doc_embeddings)\n",
        "sims.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NOJ24ridab-D"
      },
      "source": [
        "Vemos la similitud del primer documento al resto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln_L5PW7ab-D",
        "outputId": "475e2273-e1a4-4ff1-e4dd-70d39f57707c"
      },
      "outputs": [],
      "source": [
        "sims[0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIyI6Qlaab-D",
        "outputId": "02dcfcbb-24a5-4b30-f458-ccabc2137790"
      },
      "outputs": [],
      "source": [
        "sims[0, :].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGPYU3Hvab-D",
        "outputId": "079bd32a-ccd6-4a7c-aadc-6ef47c812d8c"
      },
      "outputs": [],
      "source": [
        "#Ordenamos de mayor a menor\n",
        "sims_sorted = sorted(enumerate(sims[0,:]), key=lambda item: -item[1])\n",
        "print(sims_sorted[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "KPF-pJMd6IWF",
        "outputId": "5a1057d8-e09b-4c56-d756-a354036dffa3"
      },
      "outputs": [],
      "source": [
        "#Noticia más cercana\n",
        "display(docs[sims_sorted[1][0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1RvZ2-b6IWG",
        "outputId": "4f7f2b9b-94ad-4ffa-b707-f1987afbfac2"
      },
      "outputs": [],
      "source": [
        "#5 noticias más similares\n",
        "for idx, score in sims_sorted[1:6]:\n",
        "        print(docs[idx], f\"(Score: {score})\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbFvMPak6IWG"
      },
      "outputs": [],
      "source": [
        "#Creamos un texto nuevo y buscamos la noticia más similar\n",
        "texto = \"\"\"the new Pakistan government falled in the terrorist attack by the islamic group Hamas\"\"\"\n",
        "texto_embedding = encode(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI91sX_d6IWI",
        "outputId": "53248f7d-3448-48d2-a65b-c8f5d1f37af8"
      },
      "outputs": [],
      "source": [
        "texto_embedding.reshape(1,-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_FobCM_6IWI",
        "outputId": "5624d727-7663-4bc7-a510-217045027922"
      },
      "outputs": [],
      "source": [
        "#Comparamos con el resto\n",
        "sims = cosine_similarity(texto_embedding.reshape(1,-1), doc_embeddings)[0]\n",
        "sims_sorted = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "sims.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW7qcC9Hab-F",
        "outputId": "f9d6d1a7-dfed-4f10-9c50-26b45b426266"
      },
      "outputs": [],
      "source": [
        "print(sims_sorted[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgYfqF7e6IWI",
        "outputId": "48b15067-2112-4bca-bc00-8ffa49f67d59"
      },
      "outputs": [],
      "source": [
        "#5 noticias más similares\n",
        "for idx, score in sims_sorted[0:5]:\n",
        "        print(docs[idx], f\"(Score: {score})\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryJ_FzVB6IWI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
