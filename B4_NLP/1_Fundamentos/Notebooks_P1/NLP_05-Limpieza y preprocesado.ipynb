{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d37b2223",
   "metadata": {},
   "source": [
    "### División de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91405af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import es_core_news_md\n",
    "nlp = es_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d4cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"La gata de Juan es blanca.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16dcd02a",
   "metadata": {},
   "source": [
    "División en *tokens*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cbe056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[La, gata, de, Juan, es, blanca, .]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f769a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['La', 'gata', 'de', 'Juan', 'es', 'blanca', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.text for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03092742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['la', 'gata', 'de', 'juan', 'es', 'blanca', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.lower_ for t in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "124f4bb9",
   "metadata": {},
   "source": [
    "División en frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7956e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"la vaca come hierba. El perro come longanizas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e90eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[la vaca come hierba., El perro come longanizas.]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cc5795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['la vaca come hierba.', 'El perro come longanizas.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.text for s in doc.sents]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cad131b",
   "metadata": {},
   "source": [
    "### Limpieza de acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db33cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Some Accented text'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "data = 'Sómě Áccěntěd tëxt'\n",
    "normal = unicodedata.normalize('NFKD', data).encode('ASCII', 'ignore')\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7298f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83e228c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_accents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e453d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import deaccent\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.deaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e9c1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaccent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac6116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function deaccent in module gensim.utils:\n",
      "\n",
      "deaccent(text)\n",
      "    Remove letter accents from the given string.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    text : str\n",
      "        Input string.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    str\n",
      "        Unicode string without accents.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    .. sourcecode:: pycon\n",
      "    \n",
      "        >>> from gensim.utils import deaccent\n",
      "        >>> deaccent(\"Šéf chomutovských komunistů dostal poštou bílý prášek\")\n",
      "        u'Sef chomutovskych komunistu dostal postou bily prasek'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(deaccent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c038db54",
   "metadata": {},
   "source": [
    "### Limpieza de caracteres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d00164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'007 Not sure if this  was fun 558923 What do you think of it 500USD'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pat = f'[{re.escape(string.punctuation)}]'\n",
    "    return re.sub(pat, '', text)\n",
    " \n",
    "remove_special_characters(\"007 Not sure@ if this % was #fun! 558923 What do# you think** of it.? $500USD!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5978aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9077d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mr. #Potato! is cool.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093eecf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Mr., #, Potato, !, is, cool, .]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp_en(text)\n",
    "[t for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806f69a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Mr., False),\n",
       " (#, True),\n",
       " (Potato, False),\n",
       " (!, True),\n",
       " (is, False),\n",
       " (cool, False),\n",
       " (., True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t, t.is_punct) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e593aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr Potato is cool'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a6447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Mr., Potato, is, cool]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in doc if not t.is_punct]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3948140d",
   "metadata": {},
   "source": [
    "### Expandir contracciones\n",
    "hay que instalar la librería https://github.com/kootenpv/contractions con ```pip install contractions```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7c79438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you are happy now, are not you?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "contractions.fix(\"you're happy now, aren't you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a17863d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[you, 're, happy, now, ,, are, n't, you, ?]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp_en(\"you're happy now, aren't you?\")\n",
    "[t for t in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b06c430",
   "metadata": {},
   "source": [
    "### Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12f9567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "969b3de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5ea4688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'once', 'elsewhere', 'twelve', 'well', '‘s', 'already', 'nowhere', 'thru', 'which', 'while', 'is', 'when', 'myself', 'done', 'becoming', 'does', 'others', '‘re', 'never', 'latter', 'will', \"'m\", 'afterwards', 'amount', 'ours', 'has', 'against', 'had', 'hence', 'due', 'on', 'you', 'nobody', 'many', 'cannot', 'less', 'fifty', 'some', 'n‘t', 'perhaps', 'yours', 'me', 'during', 'get', 'such', 'former', 'much', 'something', 'twenty', 'still', 'empty', 'among', 'rather', 'should', 'under', 'those', 'keep', '’m', '’s', 'any', 'also', 'in', 'give', 'where', 'herself', '‘ll', 'even', 'without', 'their', 'anyhow', 'one', 'anything', 'i', 'why', 'the', 'all', 'mostly', 'five', 'other', 'may', 'yet', 'so', 'take', 'throughout', 'not', \"'d\", 'amongst', 'various', 'enough', 'part', 'because', 'several', 'via', 'herein', 'whether', 'into', 'fifteen', 'after', 'than', 'ever', '‘ve', 'this', \"'s\", 'just', 'meanwhile', 'own', 'upon', 'front', 'make', 'serious', 'whereupon', 'his', 'although', 'whence', 'who', 'thence', 'how', 'alone', 'thereafter', 'together', 'call', 'until', 'must', '’re', 'off', 'six', 'sometime', 'full', 'nor', 'hereupon', 'she', 'were', '‘m', 'be', 'could', 'wherein', 'are', 'eleven', 'bottom', 'whole', 'no', 'hers', 're', 'hundred', 'we', 'whenever', 'do', 'might', 'within', 'using', 'but', 'her', 'anyone', 'seems', 'indeed', 'did', 'always', 'show', 'three', 'hereafter', 'nothing', 'sixty', 'say', 'through', 'below', 'of', 'someone', 'along', 'whither', 'formerly', 'whereby', 'see', \"n't\", 'eight', 'made', 'was', 'doing', 'neither', 'moreover', 'across', 'regarding', 'between', 'otherwise', 'unless', 'if', 'besides', 'side', 'hereby', \"'re\", \"'ll\", 'with', 'whatever', 'further', 'up', 'became', 'above', 'back', 'except', 'am', 'us', 'thereupon', 'sometimes', 'down', 'somewhere', '’ve', 'about', 'same', 'least', 'each', 'next', 'ca', 'yourself', 'from', 'else', 'that', 'have', 'as', 'being', 'since', 'over', 'become', 'now', 'out', 'put', 'nine', 'really', 'then', 'everywhere', 'can', 'and', 'yourselves', 'an', 'nevertheless', 'by', 'beforehand', 'thus', 'forty', '’d', 'n’t', '’ll', 'last', 'themselves', 'at', 'thereby', 'whom', 'them', 'it', 'seemed', 'whereas', 'very', 'before', 'toward', 'therefore', 'latterly', 'both', 'therein', 'our', 'its', 'onto', 'only', 'wherever', 'becomes', 'everything', 'seem', 'anyway', 'these', 'whose', 'third', 'often', 'however', 'please', 'almost', 'somehow', 'himself', 'around', 'none', 'your', 'first', '‘d', 'per', 'here', 'four', 'whereafter', 'two', 'go', 'name', 'they', 'quite', 'a', 'itself', 'would', \"'ve\", 'ten', 'beside', 'move', 'there', 'towards', 'what', 'him', 'to', 'noone', 'anywhere', 'again', 'seeming', 'my', 'namely', 'beyond', 'been', 'most', 'behind', 'another', 'mine', 'either', 'every', 'though', 'or', 'more', 'top', 'ourselves', 'few', 'he', 'for', 'everyone', 'too', 'used', 'whoever'}\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fceb69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n",
      "{'once', 'ir', 'verdadera', 'era', 'cinco', 'ser', 'como', 'vais', 'siempre', 'estados', 'sido', 'conocer', 'quienes', 'otras', 'cierta', 'días', 'el', 'propia', 'usan', 'última', 'algo', 'dia', 'misma', 'nosotros', 'paìs', 'nunca', 'mías', 'otros', 'nuevas', 'sola', 'cualquier', 'primeros', 'podría', 'podrían', 'consiguen', 'esas', 'fue', 'mencionó', 'mas', 'sean', 'tras', 'toda', 'fin', 'haceis', 'poco', 'varias', 'cuantas', 'uno', 'mejor', 'serán', 'podrias', 'tampoco', 'vamos', 'cuatro', 'una', 'último', 'agregó', 'ningunos', 'que', 'te', 'adelante', 'me', 'por', 'teneis', 'mía', 'vez', 'sea', 'ellas', 'yo', 'añadió', 'antes', 'mientras', 'existe', 'hoy', 'pues', 'están', 'cuánto', 'voy', 'cuánta', 'hasta', 'apenas', 'nosotras', 'y', 'arriba', 'sabe', 'sigue', 'o', 'ver', 'sé', 'cuándo', 'si', 'ésas', 'vuestra', 'muchos', 'dias', 'todavía', 'vosotras', 'incluso', 'creo', 'menos', 'mucho', 'tuyos', 'él', 'quizas', 'encima', 'modo', 'hace', 'será', 'éstas', 'algún', 'demás', 'cuenta', 'estado', 'mia', 'todos', 'podriamos', 'contra', 'demasiado', 'ésa', 'ahí', 'hecho', 'cómo', 'haciendo', 'podemos', 'con', 'anterior', 'ninguno', 'pero', 'hacerlo', 'sus', 'usamos', 'bastante', 'dentro', 'ningunas', 'ésta', 'les', 'solo', 'atras', 'tanto', 'usa', 'sabes', 'tú', 'dar', 'ella', 'estuvo', 'dice', 'han', 'e', 'mismas', 'tendrán', 'da', 'tengo', 'manifestó', 'últimas', 'suya', 'tan', 'hubo', 'habrá', 'poder', 'verdadero', 'todo', 'breve', 'hablan', 'propias', 'quizá', 'despues', 'al', 'manera', 'es', 'mismos', 'puedo', 'debido', 'aquella', 'estar', 'parte', 'tuya', 'dijo', 'cada', 'tercera', 'estaban', 'igual', 'aquellas', 'sería', 'alguna', 'dicho', 'ustedes', 'vuestras', 'aquéllos', 'las', 'tu', 'después', 'propios', 'sabemos', 'vuestro', 'aquí', 'ocho', 'nuestros', 'no', 'tienen', 'sobre', 'largo', 'hacemos', 'hicieron', 'bien', 'medio', 'dejó', 'nuestro', 'algunas', 'éste', 'mío', 'tenía', 'trata', 'esto', 'hago', 'ademas', 'otra', 'fuimos', 'aunque', 'ése', 'mio', 'ante', 'primero', 'de', 'usais', 'fueron', 'propio', 'usted', 'tercero', 'nuestra', 'esta', 'ambos', 'consigue', 'durante', 'gran', 'ha', 'poca', 'llegó', 'ultimo', 'quien', 'solos', 'cuando', 'cuantos', 'respecto', 'realizó', 'cual', 'lleva', 'tenga', 'explicó', 'diferente', 'tuyas', 'ésos', 'nada', 'saber', 'podeis', 'conmigo', 'podria', 'realizado', 'uso', 'sí', 'suyos', 'míos', 'se', 'mis', 'supuesto', 'mucha', 'tambien', 'eso', 'próximo', 'vaya', 'afirmó', 'mayor', 'nueve', 'también', 'nos', 'veces', 'quizás', 'cuales', 'junto', 'quiénes', 'habla', 'vosotros', 'aquél', 'tal', 'estará', 'aquellos', 'según', 'tus', 'total', 'aquello', 'diferentes', 'temprano', 'pudo', 'soy', 'mismo', 'siete', 'allí', 'además', 'estan', 'le', 'mal', 'nuevos', 'poner', 'estos', 'somos', 'verdad', 'sabeis', 'conseguir', 'dan', 'quiza', 'solas', 'quién', 'próximos', 'cuanto', 'saben', 'doce', 'pocos', 'señaló', 'porque', 'parece', 'hizo', 'delante', 'habia', 'aproximadamente', 'final', 'pesar', 'mediante', 'lado', 'consigo', 'tenido', 'está', 'sois', 'ti', 'haces', 'aseguró', 'expresó', 'ningún', 'ni', 'podriais', 'dado', 'hemos', 'van', 'eramos', 'decir', 'éstos', 'informo', 'varios', 'comentó', 'vuestros', 'menudo', 'grande', 'segun', 'muchas', 'segunda', 'indicó', 'tenemos', 'podrán', 'embargo', 'detras', 'estais', 'dio', 'cierto', 'podrian', 'luego', 'todavia', 'buen', 'contigo', 'qué', 'mias', 'pasado', 'así', 'haber', 'estamos', 'deprisa', 'suyas', 'unos', 'hacia', 'debajo', 'diez', 'buenos', 'u', 'estas', 'habían', 'peor', 'eres', 'pueden', 'otro', 'primera', 'realizar', 'aquélla', 'sin', 'día', 'pocas', 'más', 'repente', 'cuántas', 'aquéllas', 'informó', 'aún', 'lo', 'mios', 'tuvo', 'primer', 'estoy', 'aqui', 'casi', 'ahora', 'buenas', 'mi', 'esos', 'tendrá', 'ciertos', 'cuál', 'posible', 'debe', 'cuanta', 'segundo', 'proximo', 'enfrente', 'podrá', 'ahi', 'quedó', 'conseguimos', 'llevar', 'hacen', 'fui', 'son', 'grandes', 'deben', 'usar', 'existen', 'detrás', 'del', 'dieron', 'ya', 'salvo', 'siendo', 'dónde', 'excepto', 'tiene', 'consigues', 'este', 'ellos', 'últimos', 'bajo', 'aquel', 'buena', 'tres', 'unas', 'ese', 'hay', 'nuestras', 'pasada', 'despacio', 'considera', 'fuera', 'los', 'ello', 'cuántos', 'alrededor', 'qeu', 'enseguida', 'usas', 'a', 'ciertas', 'pronto', 'había', 'partir', 'os', 'va', 'nuevo', 'ninguna', 'sera', 'estaba', 'haya', 'su', 'mí', 'nadie', 'muy', 'desde', 'sólo', 'aun', 'pueda', 'tarde', 'en', 'hacer', 'algunos', 'donde', 'asi', 'encuentra', 'cuáles', 'acuerdo', 'través', 'tuyo', 'solamente', 'queremos', 'claro', 'eras', 'suyo', 'bueno', 'entonces', 'puede', 'siguiente', 'sino', 'la', 'seis', 'un', 'tener', 'todas', 'consideró', 'alli', 'dos', 'dicen', 'nueva', 'dijeron', 'he', 'quiere', 'alguno', 'para', 'eran', 'esa', 'entre'}\n"
     ]
    }
   ],
   "source": [
    "print(len(nlp.Defaults.stop_words))\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d1e725b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(La, True),\n",
       " (gata, False),\n",
       " (de, True),\n",
       " (Juan, False),\n",
       " (es, True),\n",
       " (blanca, False),\n",
       " (., False)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"La gata de Juan es blanca.\")\n",
    "[(t, t.is_stop) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c29a8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos añadir o quitar palabras de la lista\n",
    "\n",
    "#añadir\n",
    "nlp.Defaults.stop_words.add(\"my_new_stopword\")\n",
    "nlp.Defaults.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\"}\n",
    "\n",
    "#quitar\n",
    "nlp.Defaults.stop_words.remove(\"tuya\")\n",
    "nlp.Defaults.stop_words -= {\"tuya\", \"mia\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70ea6876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"tuya\" in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9017f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text : The first time I saw Catherine she was wearing a vivid crimson dress and was nervously leafing through a magazine in my waiting room.\n",
      "Text without stopwords : time saw catherine wearing vivid crimson dress nervously leafing magazine waiting room.\n",
      "Total count of stopwords in Gensim is 337\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "gensim_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
    "text = f\"The first time I saw Catherine she was wearing a vivid crimson dress and was nervously \" \\\n",
    "       f\"leafing through a magazine in my waiting room.\"\n",
    "print(f\"Original Text : {text}\")\n",
    "print(f\"Text without stopwords : {remove_stopwords(text.lower())}\")\n",
    "print(f\"Total count of stopwords in Gensim is {len(list(gensim_stopwords))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31118832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gensim_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f1db4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'once', 'elsewhere', 'twelve', 'well', 'already', 'nowhere', 'thru', 'which', 'while', 'is', 'when', 'myself', 'done', 'becoming', 'does', 'others', 'never', 'latter', 'will', 'afterwards', 'amount', 'ours', 'has', 'against', 'had', 'hence', 'ie', 'due', 'on', 'you', 'nobody', 'many', 'cannot', 'less', 'fifty', 'some', 'perhaps', 'yours', 'me', 'during', 'inc', 'get', 'such', 'former', 'much', 'something', 'twenty', 'still', 'empty', 'among', 'rather', 'should', 'under', 'etc', 'those', 'keep', 'any', 'also', 'where', 'give', 'in', 'herself', 'even', 'without', 'didn', 'their', 'anyhow', 'one', 'kg', 'anything', 'i', 'why', 'the', 'mill', 'all', 'mostly', 'con', 'don', 'five', 'other', 'may', 'yet', 'ltd', 'so', 'take', 'throughout', 'not', 'system', 'amongst', 'various', 'enough', 'part', 'several', 'because', 'via', 'fire', 'herein', 'whether', 'into', 'fifteen', 'hasnt', 'after', 'than', 'ever', 'this', 'just', 'thin', 'meanwhile', 'own', 'upon', 'front', 'make', 'serious', 'whereupon', 'his', 'although', 'whence', 'who', 'thence', 'how', 'thereafter', 'alone', 'together', 'call', 'until', 'must', 'off', 'six', 'sometime', 'full', 'nor', 'hereupon', 'she', 'were', 'be', 'could', 'wherein', 'are', 'eleven', 'bottom', 'whole', 'no', 'hers', 're', 'we', 'hundred', 'whenever', 'do', 'might', 'within', 'cant', 'using', 'but', 'her', 'anyone', 'de', 'seems', 'indeed', 'did', 'always', 'km', 'show', 'three', 'hereafter', 'nothing', 'sixty', 'say', 'through', 'below', 'of', 'someone', 'along', 'whither', 'formerly', 'whereby', 'see', 'eight', 'made', 'was', 'doing', 'neither', 'moreover', 'fill', 'across', 'regarding', 'between', 'otherwise', 'unless', 'if', 'besides', 'side', 'hereby', 'with', 'detail', 'whatever', 'up', 'further', 'became', 'eg', 'above', 'back', 'except', 'am', 'us', 'thereupon', 'sometimes', 'down', 'somewhere', 'about', 'same', 'find', 'least', 'each', 'next', 'yourself', 'from', 'interest', 'else', 'that', 'have', 'as', 'being', 'describe', 'since', 'over', 'become', 'now', 'out', 'put', 'nine', 'really', 'sincere', 'then', 'everywhere', 'can', 'and', 'co', 'yourselves', 'an', 'nevertheless', 'by', 'beforehand', 'thus', 'forty', 'doesn', 'last', 'themselves', 'at', 'thereby', 'whom', 'found', 'them', 'it', 'seemed', 'bill', 'whereas', 'very', 'before', 'toward', 'thick', 'therefore', 'latterly', 'both', 'therein', 'our', 'its', 'onto', 'only', 'wherever', 'becomes', 'everything', 'seem', 'anyway', 'these', 'whose', 'third', 'often', 'however', 'please', 'almost', 'somehow', 'himself', 'around', 'none', 'your', 'first', 'per', 'here', 'computer', 'four', 'whereafter', 'two', 'they', 'name', 'go', 'quite', 'couldnt', 'itself', 'a', 'would', 'ten', 'beside', 'move', 'there', 'towards', 'what', 'him', 'to', 'noone', 'anywhere', 'again', 'seeming', 'my', 'namely', 'beyond', 'been', 'most', 'behind', 'another', 'mine', 'either', 'un', 'every', 'though', 'or', 'more', 'top', 'ourselves', 'few', 'he', 'for', 'amoungst', 'everyone', 'too', 'cry', 'used', 'whoever'})\n"
     ]
    }
   ],
   "source": [
    "print(gensim_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06bc0de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'not' in gensim_stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0221b482",
   "metadata": {},
   "source": [
    "### Corrección ortográfica\n",
    "Librería `spellchecker`. Instalamos con\n",
    "```pip install pyspellchecker```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c0db4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspellchecker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpellChecker\n\u001b[1;32m      3\u001b[0m spell \u001b[38;5;241m=\u001b[39m SpellChecker(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Spanish dictionary\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHay \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspell\u001b[38;5;241m.\u001b[39mword_frequency\u001b[38;5;241m.\u001b[39m_unique_words\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m palabras en el diccionario\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ia/lib/python3.10/site-packages/spellchecker/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m  \u001b[38;5;21;01mspellchecker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Spellchecker,getInstance\n",
      "File \u001b[0;32m~/anaconda3/envs/ia/lib/python3.10/site-packages/spellchecker/core.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minexactsearch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mindexer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictionaryIndex\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _detect_lang\n\u001b[1;32m     29\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpellchecker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetInstance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'indexer'"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(language='es')  # Spanish dictionary\n",
    "print(f\"Hay {spell.word_frequency._unique_words} palabras en el diccionario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.correction('mañnaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.candidates('mañnaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce821857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si una palabra está en el diccionario devuelve su frecuencia relativa:\n",
    "spell['mañana']  #equivale a spell.word_frequency['mañana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell['mañna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2881dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.correction('mañana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.candidates(\"adiós\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell[\"adios\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4775d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell[\"adiós\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a73364",
   "metadata": {},
   "source": [
    "### Lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"los gatos son blancos\")\n",
    "[t.lemma_ for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c892231",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"La salida se ha bloqueado. La salida está bloqueada.\")\n",
    "[(t.lemma_, t.pos_) for t in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0651bc93",
   "metadata": {},
   "source": [
    "### Funciones de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31604e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"@Graffitera23 qué hermoso!,es bueno desviar la mirada al cielo y a las nubes de vez en cuando,abajo está jodido.Preciosa foto,mil abrazos \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en spacy\n",
    "import re\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_md')\n",
    "               \n",
    "def normalize_document(doc):\n",
    "   # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # quitamos puntuación/espacios y stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if not t.is_stop and not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_document(texto)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5671a4fc",
   "metadata": {},
   "source": [
    "Con esta función no se eliminan los signos de puntuación que no forman un token de manera independiente, debemos hacerlo con un patrón regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b372ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "stop_words = ['es', 'y', 'a']\n",
    "\n",
    "pat  = '[{}]'.format(re.escape(string.punctuation))\n",
    "\n",
    "def normalize_document_remove_punct(doc):\n",
    "   # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # quitamos puntuación/espacios y stopwords\n",
    "    filtered_tokens = [re.sub(pat, ' ', t.lower_) for t in tokens if not t.text in stop_words and not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_document_remove_punct(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess\n",
    "\n",
    "help(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b755820",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_preprocess(texto, deacc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.tokenize\n",
    "\n",
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52717a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tokenize(texto, deacc=True, lowercase=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427964ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "#https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string\n",
    "help(preprocess_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"<i>Hel 9lo</i> <b>Wo9 rld</b>! Th3     weather_is really g00d today, isn't it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757abb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import *\n",
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ba0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords, stem_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf9182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
