{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling (librería Gensim)\n",
    "Vamos a ver cómo realizar un modelado de temática en grandes volúmenes de texto con la librería `gensim`  \n",
    "\n",
    "Utilizaremos el conjunto de datos *Lee* de `Gensim` (es una versión abreviada del conjunto http://www.socsci.uci.edu/~mdlee/lee_pincombe_welsh_document.PDF).  \n",
    "\n",
    "Para visualizar gráficamente los tópicos es necesario instalar la librería `pyLDAvis` dentro del entorno de Anaconda con el comando:\n",
    "```python\n",
    "conda install -c conda-forge pyldavis \n",
    "```\n",
    "\n",
    "### Cargamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# spacy para lematizar\n",
    "import spacy\n",
    "\n",
    "# herramientas de dibujado\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos un generador para obtener los documentos del Corpus línea a línea desde el archivo del conjunto de ejemplo y convertirlos en un listado de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "stop_words = nlp.Defaults.stop_words #listado de stop-words\n",
    "\n",
    "def lemmatize_doc(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PROPN']):\n",
    "    \"\"\"Función que devuelve el lema de una string,\n",
    "    excluyendo las palabras cuyo POS_TAG no está en la lista\"\"\"\n",
    "    text_out = [t.lemma_.lower() for t in nlp(text)\n",
    "                if t.pos_ in allowed_postags\n",
    "                and len(t.lemma_)>3\n",
    "                and not t.is_stop]\n",
    "    return text_out\n",
    "            \n",
    "def build_texts(fname):\n",
    "    \"\"\"\n",
    "    Generador que devuelve el texto tokenizado a partir de un archivo\n",
    "    línea a línea\n",
    "    \"\"\"\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            yield lemmatize_doc(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lee_data_file = 'lee_background.cor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lee_data_file) as f:\n",
    "        for line in f:\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto=build_texts(lee_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto1 = next(texto)\n",
    "print(texto1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in texto:\n",
    "    print(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_procesado = [c for c in texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_procesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = build_texts(lee_data_file)\n",
    "corpus = [c for c in texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el diccionario usando el generador para no cargar el corpus completo en memoria. Luego lo usamos para generar el BoW directamente desde el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea diccionario\n",
    "diccionario = corpora.Dictionary(build_texts(lee_data_file))\n",
    "# Crea corpus (BoW)\n",
    "corpus = [diccionario.doc2bow(text) for text in build_texts(lee_data_file)]\n",
    "\n",
    "# Vemos como ejemplo el primer doc\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario.num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionario.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=4, id2word=diccionario, iterations=5000)\n",
    "pprint(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus[201]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los temas  \n",
    "Podemos visualizarlo gráficamente la distribución de los documentos del Corpus por temas con la librería `pyLDAvis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = gensimvis.prepare(ldamodel, corpus, diccionario)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos bigramas y trigramas\n",
    "Creamos un modelo para las palabras más frecuentes como bigrama o trigrama para considerar estos tokens juntos en lugar de separados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(build_texts(lee_data_file), min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "#optimizamos una vez entreando\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo los bigramas que ha encontrado para el documento con índice 1 son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigram_mod[texto1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos trigramas\n",
    "trigram = gensim.models.Phrases(bigram_mod[build_texts(lee_data_file)], min_count=5, threshold=50)  \n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "def make_trigrams(text):\n",
    "    '''Devuelve un doc convertido en trigramas según el\n",
    "    modelo trigram_mod. La entrada tiene que ser una lista\n",
    "    de de tokens'''\n",
    "    return trigram_mod[bigram_mod[text]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular los trigramas, aplicamos este modelo sobre la salida del modelo de bigramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trigram_mod[bigram_mod[texto1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_trigrams(texto1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los bigramas y trigramas que ha encontrado en el documento con una búsqueda de patrones regulares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentence = ' '.join(make_trigrams(texto1))\n",
    "re.findall(r'\\w+_\\w+', trigram_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos el corpus de texto con el modelo de trigramas. Usamos la función de tipo iterador `map` para no cargar todo el corpus intermedio en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_trigramas = map(make_trigrams, build_texts(lee_data_file)) #aplica modelo trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(textos_trigramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(textos_trigramas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el diccionario y el corpus para Topic Modeling\n",
    "Las dos entradas para el modelo LDA son un diccionario de `gensim` y un corpus de texto.  \n",
    "Preparamos el diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea diccionario\n",
    "textos_trigramas = map(make_trigrams, build_texts(lee_data_file)) #aplica modelo trigramas\n",
    "diccionario = corpora.Dictionary(textos_trigramas)\n",
    "# Crea corpus (BoW)\n",
    "textos_trigramas = map(make_trigrams, build_texts(lee_data_file)) #aplica modelo trigramas\n",
    "corpus = [diccionario.doc2bow(text) for text in textos_trigramas]\n",
    "\n",
    "# Vemos como ejemplo el primer doc\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionario.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que en el modelo BoW de `gensim` el primer elemento de cada tupla es el ID del término en el diccionario, y el segundo su frecuencia en el doc.  \n",
    "`diccionario[ID]` devuelve el término con índice ID en el vocabulario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(diccionario[id], freq) for id, freq in corpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling\n",
    "\n",
    "### Modelo LSI\n",
    "Este modelo ordena los temas y saca un listado ordenado. Hay que especificar el número de topics.\n",
    "\n",
    "Vamos a usar el algoritmo Latent Dirichlet Allocation (LDA) de `gensim` con la implementación multicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=4, id2word=diccionario)\n",
    "pprint(lsimodel.show_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicamos el modelo sobre el texto 2\n",
    "lsimodel[corpus[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo LDA\n",
    "Es un modelo generativo que considera cada documento como una mezcla de temas donde cada tema tiene una distribución de las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=diccionario, iterations=500)\n",
    "pprint(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.matutils.corpus2dense(ldamodel[corpus], ldamodel.num_topics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los temas  \n",
    "Podemos visualizarlo gráficamente la distribución de los documentos del Corpus por temas con la librería `pyLDAvis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = gensimvis.prepare(ldamodel, corpus, diccionario)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la separación de temas no es muy buena porque hay algunas palabras muy frecuentes que aparecen en todos los temas. Podemos filtrar estas palabras antes de realizar el LDA del Corpus mediante el método `filter_extremes` de la clase `Dictionary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario.filter_extremes(no_above=0.7) #filtramos las palabras que aparecen en más del 70% de los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionario.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a calcular la matriz LDA del Corpus y la representamos gráficamente para ver si es más expresiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea corpus (BoW)\n",
    "textos_trigramas = map(make_trigrams, build_texts(lee_data_file))\n",
    "corpus = [diccionario.doc2bow(text) for text in textos_trigramas]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica el modelo LDA\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=4, id2word=diccionario, iterations=500)\n",
    "\n",
    "# Representa gráficamente\n",
    "vis_data = gensimvis.prepare(ldamodel, corpus, diccionario)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del número de temas\n",
    "Para seleccionar el número óptimo de temas, debemos hacer un barrido y seleccionar el modelo con mayor valor de coherencia (Topic coherence).  \n",
    "Lo podemos automatizar en una función (nota: *tarda bastante en ejecutarse*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit, start=1, step=1):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    start: min number of topics\n",
    "    step: step between topics number swept\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    n_topics = list(range(start, limit, step))\n",
    "    for num_topics in n_topics:\n",
    "        lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "    \n",
    "    return lm_list, c_v, n_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_trigramas = list(map(make_trigrams, build_texts(lee_data_file)))\n",
    "\n",
    "lmlist, c_v, n = evaluate_graph(dictionary=diccionario, corpus=corpus, texts=textos_trigramas, limit=20, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinar el tema dominante en cada documento\n",
    "Una aplicación práctica del topic modeling es determinar de qué tema trata un documento.  \n",
    "Para hacer esto, se busca el número de tema que tiene una mayor contribución en el documento.  \n",
    "La función `format_topics_sentences()` genera esta información en forma de tabla.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus):\n",
    "    # inicializa salida\n",
    "    sent_topics = []\n",
    "\n",
    "    # obtiene main topic de cada documento\n",
    "    for row in ldamodel[corpus]:\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        (topic_num, prop_topic)=row[0]\n",
    "        wp = ldamodel.show_topic(topic_num)\n",
    "        topic_keywords = \", \".join([word for word, prop in wp])\n",
    "        sent_topics.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]))\n",
    "    sent_topics_df = pd.DataFrame(sent_topics)\n",
    "    sent_topics_df.reset_index(inplace=True)\n",
    "    sent_topics_df.columns = ['No_doc','Tema_dominante', 'Contribucion_per', 'Palabras_clave']\n",
    "    sent_topics_df['Tema_dominante'] = sent_topics_df['Tema_dominante'].astype('int')\n",
    "    return(pd.DataFrame(sent_topics_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamodel, corpus=corpus)\n",
    "\n",
    "df_topic_sents_keywords.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel[corpus[37]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinar el documento más representativo de cada tema\n",
    "Agrupando por temas, podemos seleccionar el de mayor porcentaje como más representativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos documentos por tema\n",
    "sent_topics_sorted = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Tema_dominante')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorted = pd.concat([sent_topics_sorted, \n",
    "                                             grp.sort_values(['Contribucion_per'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# cambiamos nombre de columna\n",
    "sent_topics_sorted.columns = df_topic_sents_keywords.columns\n",
    "\n",
    "# Mostramos\n",
    "sent_topics_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de temas entre documentos\n",
    "Por último, podemos analizar el volumen y la distribución de temas entre los documentos del tema.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# núm de documentos por cada tema\n",
    "topic_counts = df_topic_sents_keywords['Tema_dominante'].value_counts()\n",
    "\n",
    "# porcentaje de documentos por cada tema\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# palabras clave de cada tema\n",
    "topic_num_keywords = sent_topics_sorted[['Tema_dominante', 'Palabras_clave']]\n",
    "\n",
    "# Concatenamos por columna\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# cambiamos nombre de columna\n",
    "df_dominant_topics.columns = ['Tema_dominante', 'Palabras_clave', 'Num_Documentos', 'Perc_Documentos']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación de temáticas para un documento nuevo\n",
    "Procesamos el nuevo documento por todo el flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia = \"A bushfire broke out early this morning in the rural community of \\\n",
    "    Myall Creek, New South Wales, prompting local authorities to issue evacuation \\\n",
    "    warnings. The fire, fueled by dry conditions and strong winds, has scorched \\\n",
    "    approximately 50 hectares of farmland. Emergency services are on site, battling \\\n",
    "    the blaze with both ground crews and aerial firefighting units\"\n",
    "\n",
    "noticia_bow = diccionario.doc2bow(make_trigrams(lemmatize_doc(noticia)))\n",
    "noticia_topics = ldamodel[noticia_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(noticia_topics, key=lambda x: (x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
