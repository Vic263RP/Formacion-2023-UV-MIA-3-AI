{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de características TF-IDF\n",
    "\n",
    "Primero importamos todas las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "pd.options.display.max_colwidth = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el mismo conjunto de textos de ejemplo *(CORPUS)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['El cielo es azul y bonito',\n",
    "          'Me encanta el cielo azul, pero no el cielo plomizo',\n",
    "          'Bonito cielo hacía ese día',\n",
    "          'Hoy he desayunado huevos con jamón y tostadas',\n",
    "          'Juan odia las tostadas y los huevos con jamón',\n",
    "          'las tostadas de jamón están muy buenas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del texto\n",
    "Definimos una función simple de limpieza y normalización del texto y la aplicamos a nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "def normalizar_doc(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas mayores de 3 caracteres'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       len(t.text)>3 and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus = list(map(normalizar_doc, corpus))\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo TF-IDF\n",
    "Este modelo promedia la frecuencia de aparición de cada término (TF) por el número de documentos en los que aparece el término (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(norm=None)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#también es una matriz sparse\n",
    "tv_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos los mismos atributos que en el CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vocabulario que ha aprendido es el mismo que en el caso del BoW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al calcular la matriz de vectores de documento se aplica un peso a cada término en función de su IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_matrix = tv_matrix.toarray()\n",
    "vocab = tv.get_feature_names_out()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pesos para cada término (valor idf(t))\n",
    "tv.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(palabra, peso) for palabra, peso in zip(tv.get_feature_names_out(), tv.idf_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La frecuencia de documentos para cada término (valor tf(término, documento)) no se almacena directamente en el vectorizador pero se puede calcular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.sum(tv_matrix>0, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frec. de documentos y peso IDF para cada término\n",
    "pd.DataFrame({'término':vocab, 'freq':df, 'idf':tv.idf_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La matriz TF-IDF es la BoW multiplicada por los pesos IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(norm_corpus).toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.round(cv_matrix*tv.idf_, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de los pesos IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fórmula de scikit-learn\n",
    "#idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1\n",
    "n = tv_matrix.shape[0]\n",
    "np.log((n+1)/(1+df))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fórmula estándar para TF-IDF\n",
    "#idf(t) = log [ n / (df(t)] + 1 \n",
    "np.log(n/(df))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si normalizamos, se ajustan los valores tf-idf en cada documento según la norma 'l2' (suma de cuadrados) o 'l1' (suma de valores absolutos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_l2 = TfidfVectorizer(norm='l2', use_idf=True)\n",
    "tv_matrix_l2 = tv_l2.fit_transform(norm_corpus).toarray()\n",
    "pd.DataFrame(np.round(tv_matrix_l2, 2), columns=tv_l2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(tv_matrix_l2**2, axis=1)) #cada fila está normalizada a uno (norma 'L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(tv_matrix**2, axis=1)) #valores de cada documento sin normalizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de la matriz en nuevos documentos\n",
    "Hay que aplicar el método `transform` siempre que queremos vectorizar un nuevo conjunto de documentos.\\\n",
    "Al calcular la matriz TF-IDF para el nuevo corpus, el peso de cada término (IDF) no se modifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_corpus = ['El Cielo amenaza lluvia', 'Pedro desayuna tostadas de jamón con tomate']\n",
    "norm_nuevo_corpus = list(map(normalizar_doc, nuevo_corpus))\n",
    "new_matrix=tv.transform(norm_nuevo_corpus).toarray()\n",
    "pd.DataFrame(np.round(new_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aplicamos una vectorización normalizada, se normaliza cada documento considerando sólo los términos del vocabulario.\n",
    "### Ejercicio 1\n",
    "Aplica la vectorización TF-IDF con la normalización *l2* entrenada con el corpus de ejemplo al nuevo corpus y muestra la matriz TF-IDF generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo n-gramas\n",
    "Con el vectorizador `tfidfvectorizer` también podemos especificar el rango de n-gramas y el `min_df`.\n",
    "### Ejercicio 2\n",
    "Calcula la matriz TF-IDF para el corpus de ejemplo considerando unigramas y bigramas pero sólo para los términos que aparecen al menos en 2 documentos. No apliques ninguna normalización tras vectorizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería `Gensim`\n",
    "Para trabajar con la librería `Gensim` es necesario transformar los documentos en una lista de tokens. El modelo TF-IDF se calcula a partir del BoW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_doc_tokenize(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas mayores de 3 caracteres'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       len(t.text)>3 and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos nuestros texto de ejemplo en una lista de tokens y visualizamos el primer documento como ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = map(normalizar_doc_tokenize, corpus)\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular la matriz TF-IDF primero hay que calcular el modelo BoW:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero aprendemos las palabras y luego generamos la matriz sobre el `corpus` que queramos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "diccionario = Dictionary(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionario.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hay que volver a generar el objeto map\n",
    "mapped_corpus = [diccionario.doc2bow(text)\n",
    "                 for text in map(normalizar_doc_tokenize, corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, tf) in mapped_corpus[1]:\n",
    "    print(f\"{diccionario[i]}: {tf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto `Dictionary` guarda la frecuencia de documentos de cada término (núm. de documentos en los que aparece) en el atributo `dfs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diccionario.dfs:\n",
    "    print(f\"{diccionario[i]}: {diccionario.dfs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo TF-IDF\n",
    "Hay que hacer una transformación sobre la matriz BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "tfidf = TfidfModel(mapped_corpus)\n",
    "corpus_tfidf = tfidf[mapped_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, la librería `gensim` genera por cada documento una lista de tuplas (ID,frecuencia) donde ahora la frecuencia está normalizada por la inversa de la frecuencia de documentos que contienen el término:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo devuelve un objeto `TransformedCorpus` que se puede recorrer como un *iterable* o indexar directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, v) in corpus_tfidf[1]:\n",
    "    print(f\"{diccionario[i]}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de los modelos a nuevos textos\n",
    "Para aplicar un modelo BoW o TF-IDF a un nuevo documento hay que utilizar los modelos ya entrenados en `gensim` sobre el corpus original. Hay que calcular el BoW del nuevo corpus con el objeto `Dictionary` original y sobre esta matriz calcular su TF-IDF con el modelo `TfidfModel` entrenado con el corpus original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_nuevo_corpus = [diccionario.doc2bow(text)\n",
    "                 for text in map(normalizar_doc_tokenize, nuevo_corpus)]\n",
    "#BoW\n",
    "mapped_nuevo_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "nuevo_corpus_tfidf = tfidf[mapped_nuevo_corpus]\n",
    "nuevo_corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nuevo_corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nuevo_corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, v) in nuevo_corpus_tfidf[1]:\n",
    "    print(f\"{diccionario[i]}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando todo el proceso en un único paso\n",
    "list(tfidf[map(lambda x: diccionario.doc2bow(normalizar_doc_tokenize(x)), nuevo_corpus)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "Define una función que devuelva la matriz TF-IDF para una lista de nuevos textos (pasada como lista de *strings*) usando el diccionario y la función de normalización creadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_tfidf(corpus, diccionario=diccionario, normalizacion=normalizar_doc_tokenize, vectorizador=tfidf):\n",
    "    \"\"\"Genera la matriz TF-IDF de la lista de texto en 'corpus'\n",
    "    usando el diccionario, la función de normalización y el\n",
    "    vectorizador TF-IDF pasados como argumentos\n",
    "    Devuelve una lista de vectores\"\"\"\n",
    "    \n",
    "    #COMPLETAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcula_tfidf(nuevo_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
