{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de vectores semánticos en un clasificador *zero-shot*\n",
    "Vamos a usar el vector semántico de los documentos para realizar una clasificación sobre unas categorías definidas semánticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de textos a clasificar es un listado de compras, y cada categoría está definida por un listado de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alimentos comida bebida carne pollo jugo',\n",
       " 'alcohol cigarrillo tabaco',\n",
       " 'ropa de vestir calzado zapatos vestidos',\n",
       " 'muebles hogar aseo herramienta',\n",
       " 'salud medicamento hospital',\n",
       " 'transporte bus avión automóvil',\n",
       " 'comunicaciones teléfono celular']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargamos compras y clases\n",
    "compras = pd.read_csv(\"compras_subset.csv\", index_col=False)\n",
    "\n",
    "clases = []\n",
    "with open('clases.txt') as f:\n",
    "    clases = [line[:-1] for line in f]\n",
    "    \n",
    "clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compras.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los *word embeddings* del modelo FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de vectores en formato TXT\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wordvectors_file_vec = '~/Downloads/fasttext-sbwc.100k.vec'\n",
    "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos dos funciones para calcular la simitud semántica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def to_vector(texto):\n",
    "    \"\"\"Función para calcular vector semántico\n",
    "    de un documento\"\"\"\n",
    "    tokens = texto.lower().split()\n",
    "    vec = np.zeros(300)\n",
    "    for word in tokens:\n",
    "        # si la palabra está la acumulamos\n",
    "        if word in wordvectors:\n",
    "            vec += wordvectors[word]\n",
    "    return vec / norm(vec)\n",
    "\n",
    "def similarity(texto_1, texto_2):\n",
    "    \"\"\"Calcula la similitud semántica de dos textos\"\"\"\n",
    "    vec_1 = to_vector(texto_1)\n",
    "    vec_2 = to_vector(texto_2)\n",
    "    sim = vec_1 @ vec_2\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity(\"cielo al amanecer azul\", \"las nubes amenazan lluvia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity(\"cielo al amanecer azul\", \"jugador de fútbol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la similitud semántica para asignar cada compra a una clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra = compras.sample(1)\n",
    "texto = muestra[\"compra\"].values[0]\n",
    "clase_real = muestra[\"clase\"].values[0]\n",
    "\n",
    "sims = np.array([similarity(texto, clase) for clase in clases])\n",
    "clase_pred = np.argmax(sims)\n",
    "\n",
    "print('detalle compra:\\t', texto)\n",
    "print('clase predicha:\\t', clases[clase_pred])\n",
    "print('clase real:\\t', clases[clase_real])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular uno a uno la similitud con esta función es muy lento, lo hacemos vectorizando los corpus de compras y clases, y aplicando un producto matricial sobre estas matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pon todos los vectores de compras en una matriz\n",
    "compras_vectores = [to_vector(texto) for texto in compras[\"compra\"]]\n",
    "X = np.vstack(compras_vectores)\n",
    "\n",
    "# pon todos los vectores de clases en una matriz\n",
    "clases_vectores = [to_vector(cls) for cls in clases]\n",
    "Y = np.vstack(clases_vectores)\n",
    "\n",
    "print('X.shape =',X.shape)\n",
    "print('Y.shape =',Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#calcula las similitudes como un producto punto\n",
    "similitudes = X @ Y.T\n",
    "\n",
    "pred = np.argmax(similitudes, axis=1)\n",
    "\n",
    "print(classification_report(compras[\"clase\"], pred))\n",
    "print(\"Accuracy:\", accuracy_score(compras[\"clase\"], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
