{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de características *Bag of Words*\n",
    "\n",
    "Primero importamos todas las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "pd.options.display.max_colwidth = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un pequeño cuerpo de textos de ejemplo *(CORPUS)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['El cielo es azul y bonito',\n",
    "          'Me encanta el cielo azul, pero no el cielo plomizo',\n",
    "          'Bonito cielo hacía ese día',\n",
    "          'Hoy he desayunado huevos con jamón y tostadas',\n",
    "          'Juan odia las tostadas y los huevos con jamón',\n",
    "          'las tostadas de jamón están muy buenas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del texto\n",
    "Definimos una función simple de limpieza y normalización del texto y la aplicamos a nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "def normalizar_doc(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas mayores de 3 caracteres'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       len(t.text)>3 and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cielo azul bonito'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probamos la función\n",
    "normalizar_doc(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El cielo es azul y bonito'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo azul bonito',\n",
       " 'encanta cielo azul pero cielo plomizo',\n",
       " 'bonito cielo hacía',\n",
       " 'desayunado huevos jamón tostadas',\n",
       " 'juan odia tostadas huevos jamón',\n",
       " 'tostadas jamón están buenas']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aplicamos a todo el corpus\n",
    "norm_corpus = [normalizar_doc(doc) for doc in corpus]\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo azul bonito',\n",
       " 'encanta cielo azul pero cielo plomizo',\n",
       " 'bonito cielo hacía',\n",
       " 'desayunado huevos jamón tostadas',\n",
       " 'juan odia tostadas huevos jamón',\n",
       " 'tostadas jamón están buenas']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternativamente\n",
    "list(map(normalizar_doc, corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería `scikit-learn`\n",
    "Implementamos el modelo Bag-of-Word (BoW) con `scikit-learn`\n",
    "\n",
    "Contamos la frecuencia de aparición de los términos en cada documento, usando un vocabulario común. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(norm_corpus) #también funcionaría cv.fit(map(normalizar_doc, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_request_for_signature',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_transform_request',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo genera un diccionario con todas las palabras del vocabulario y asigna un índice único a cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['azul', 'bonito', 'buenas', 'cielo', 'desayunado', 'encanta',\n",
       "       'están', 'hacía', 'huevos', 'jamón', 'juan', 'odia', 'pero',\n",
       "       'plomizo', 'tostadas'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cielo': 3,\n",
       " 'azul': 0,\n",
       " 'bonito': 1,\n",
       " 'encanta': 5,\n",
       " 'pero': 12,\n",
       " 'plomizo': 13,\n",
       " 'hacía': 7,\n",
       " 'desayunado': 4,\n",
       " 'huevos': 8,\n",
       " 'jamón': 9,\n",
       " 'tostadas': 14,\n",
       " 'juan': 10,\n",
       " 'odia': 11,\n",
       " 'están': 6,\n",
       " 'buenas': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del vocabulario aprendido, generamos el vector BoW de cada documento creando una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_matrix = cv.transform(norm_corpus)\n",
    "cv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matriz sparse\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 13)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 14)\t1\n",
      "  (4, 8)\t1\n",
      "  (4, 9)\t1\n",
      "  (4, 10)\t1\n",
      "  (4, 11)\t1\n",
      "  (4, 14)\t1\n",
      "  (5, 2)\t1\n",
      "  (5, 6)\t1\n",
      "  (5, 9)\t1\n",
      "  (5, 14)\t1\n"
     ]
    }
   ],
   "source": [
    "#sólo guarda info de las celdas no vacías\n",
    "print(cv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada término único es una característica de la matriz generada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>buenas</th>\n",
       "      <th>cielo</th>\n",
       "      <th>desayunado</th>\n",
       "      <th>encanta</th>\n",
       "      <th>están</th>\n",
       "      <th>hacía</th>\n",
       "      <th>huevos</th>\n",
       "      <th>jamón</th>\n",
       "      <th>juan</th>\n",
       "      <th>odia</th>\n",
       "      <th>pero</th>\n",
       "      <th>plomizo</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  buenas  cielo  desayunado  encanta  están  hacía  huevos  \\\n",
       "0     1       1       0      1           0        0      0      0       0   \n",
       "1     1       0       0      2           0        1      0      0       0   \n",
       "2     0       1       0      1           0        0      0      1       0   \n",
       "3     0       0       0      0           1        0      0      0       1   \n",
       "4     0       0       0      0           0        0      0      0       1   \n",
       "5     0       0       1      0           0        0      1      0       0   \n",
       "\n",
       "   jamón  juan  odia  pero  plomizo  tostadas  \n",
       "0      0     0     0     0        0         0  \n",
       "1      0     0     0     1        1         0  \n",
       "2      0     0     0     0        0         0  \n",
       "3      1     0     0     0        0         1  \n",
       "4      1     1     1     0        0         1  \n",
       "5      1     0     0     0        0         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtenemos palabras únicas en el corpus\n",
    "vocab = cv.get_feature_names_out()\n",
    "# mostramos vectores de características BoW del corpus\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#id de las palabras del vocabulario\n",
    "cv.vocabulary_.get('cielo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si una palabra no está en el vocabulario...\n",
    "cv.vocabulary_.get('lluvia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando el modelo a nuevos documentos\n",
    "Cuando calculamos el vector BoW de un texto nuevo con el modelo no hay que volver a ajustar el vocabulario, por lo que los términos nuevos no se tendrán en cuenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo_corpus = ['El Cielo amenaza lluvia', 'Pedro desayuna tostadas de jamón con tomate']\n",
    "cv_matrix_nueva = cv.transform(map(normalizar_doc, nuevo_corpus))\n",
    "cv_matrix_nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>buenas</th>\n",
       "      <th>cielo</th>\n",
       "      <th>desayunado</th>\n",
       "      <th>encanta</th>\n",
       "      <th>están</th>\n",
       "      <th>hacía</th>\n",
       "      <th>huevos</th>\n",
       "      <th>jamón</th>\n",
       "      <th>juan</th>\n",
       "      <th>odia</th>\n",
       "      <th>pero</th>\n",
       "      <th>plomizo</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  buenas  cielo  desayunado  encanta  están  hacía  huevos  \\\n",
       "0     0       0       0      1           0        0      0      0       0   \n",
       "1     0       0       0      0           0        0      0      0       0   \n",
       "\n",
       "   jamón  juan  odia  pero  plomizo  tostadas  \n",
       "0      0     0     0     0        0         0  \n",
       "1      1     0     0     0        0         1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_matrix_nueva.toarray(), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo amenaza lluvia', 'pedro desayuna tostadas jamón tomate']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(normalizar_doc, nuevo_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos N-grams\n",
    "Considera como términos del vocabulario cada secuencia de N palabras consecutivas que aparece en el texto (*n-gramas*).  \n",
    "Por ejemplo para los *bigrams* del corpus (N=2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['azul bonito', 'azul pero', 'bonito cielo', 'cielo azul',\n",
       "       'cielo hacía', 'cielo plomizo', 'desayunado huevos',\n",
       "       'encanta cielo', 'están buenas', 'huevos jamón', 'jamón están',\n",
       "       'jamón tostadas', 'juan odia', 'odia tostadas', 'pero cielo',\n",
       "       'tostadas huevos', 'tostadas jamón'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo azul bonito',\n",
       " 'encanta cielo azul pero cielo plomizo',\n",
       " 'bonito cielo hacía',\n",
       " 'desayunado huevos jamón tostadas',\n",
       " 'juan odia tostadas huevos jamón',\n",
       " 'tostadas jamón están buenas']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul bonito</th>\n",
       "      <th>azul pero</th>\n",
       "      <th>bonito cielo</th>\n",
       "      <th>cielo azul</th>\n",
       "      <th>cielo hacía</th>\n",
       "      <th>cielo plomizo</th>\n",
       "      <th>desayunado huevos</th>\n",
       "      <th>encanta cielo</th>\n",
       "      <th>están buenas</th>\n",
       "      <th>huevos jamón</th>\n",
       "      <th>jamón están</th>\n",
       "      <th>jamón tostadas</th>\n",
       "      <th>juan odia</th>\n",
       "      <th>odia tostadas</th>\n",
       "      <th>pero cielo</th>\n",
       "      <th>tostadas huevos</th>\n",
       "      <th>tostadas jamón</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul bonito  azul pero  bonito cielo  cielo azul  cielo hacía  \\\n",
       "0            1          0             0           1            0   \n",
       "1            0          1             0           1            0   \n",
       "2            0          0             1           0            1   \n",
       "3            0          0             0           0            0   \n",
       "4            0          0             0           0            0   \n",
       "5            0          0             0           0            0   \n",
       "\n",
       "   cielo plomizo  desayunado huevos  encanta cielo  están buenas  \\\n",
       "0              0                  0              0             0   \n",
       "1              1                  0              1             0   \n",
       "2              0                  0              0             0   \n",
       "3              0                  1              0             0   \n",
       "4              0                  0              0             0   \n",
       "5              0                  0              0             1   \n",
       "\n",
       "   huevos jamón  jamón están  jamón tostadas  juan odia  odia tostadas  \\\n",
       "0             0            0               0          0              0   \n",
       "1             0            0               0          0              0   \n",
       "2             0            0               0          0              0   \n",
       "3             1            0               1          0              0   \n",
       "4             1            0               0          1              1   \n",
       "5             0            1               0          0              0   \n",
       "\n",
       "   pero cielo  tostadas huevos  tostadas jamón  \n",
       "0           0                0               0  \n",
       "1           1                0               0  \n",
       "2           0                0               0  \n",
       "3           0                0               0  \n",
       "4           0                1               0  \n",
       "5           0                0               1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab_bigram = bv.get_feature_names_out()\n",
    "pd.DataFrame(bv_matrix, columns=vocab_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede establecer el rango de n-grams a `(1,2)` para obtener el conjunto de unigramas y bigramas del corpus.  \n",
    "Para limitar el número de términos en el vocabulario del modelo BoW se puede limitar a los términos que aparecen en un mínimo de documentos con el parámetro `min_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>cielo</th>\n",
       "      <th>cielo azul</th>\n",
       "      <th>huevos</th>\n",
       "      <th>huevos jamón</th>\n",
       "      <th>jamón</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  cielo  cielo azul  huevos  huevos jamón  jamón  tostadas\n",
       "0     1       1      1           1       0             0      0         0\n",
       "1     1       0      2           1       0             0      0         0\n",
       "2     0       1      1           0       0             0      0         0\n",
       "3     0       0      0           0       1             1      1         1\n",
       "4     0       0      0           0       1             1      1         1\n",
       "5     0       0      0           0       0             0      1         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv = CountVectorizer(ngram_range=(1,2), min_df=2)\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab_bigram = bv.get_feature_names_out()\n",
    "pd.DataFrame(bv_matrix, columns=vocab_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "Aplica el último modelo de BoW (unigramas y bigramas con min_df=2) al nuevo corpus de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azul</th>\n",
       "      <th>bonito</th>\n",
       "      <th>cielo</th>\n",
       "      <th>cielo azul</th>\n",
       "      <th>huevos</th>\n",
       "      <th>huevos jamón</th>\n",
       "      <th>jamón</th>\n",
       "      <th>tostadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azul  bonito  cielo  cielo azul  huevos  huevos jamón  jamón  tostadas\n",
       "0     0       0      1           0       0             0      0         0\n",
       "1     0       0      0           0       0             0      1         1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#completar\n",
    "bv_matrix = bv.transform(map(normalizar_doc, nuevo_corpus))\n",
    "pd.DataFrame(bv_matrix.toarray(), columns=vocab_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería `Gensim`\n",
    "Para trabajar con la librería `Gensim` es necesario transformar los documentos en una lista de tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos nuestros texto de ejemplo en una lista de tokens y visualizamos el primer documento como ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_doc_tokenize(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas mayores de 3 caracteres'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       len(t.text)>3 and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cielo', 'azul', 'bonito']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizar_doc_tokenize(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cielo azul bonito'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizar_doc(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cielo', 'azul', 'bonito'],\n",
       " ['encanta', 'cielo', 'azul', 'pero', 'cielo', 'plomizo'],\n",
       " ['bonito', 'cielo', 'hacía'],\n",
       " ['desayunado', 'huevos', 'jamón', 'tostadas'],\n",
       " ['juan', 'odia', 'tostadas', 'huevos', 'jamón'],\n",
       " ['tostadas', 'jamón', 'están', 'buenas']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [normalizar_doc_tokenize(doc) for doc in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cielo', 'azul', 'bonito'],\n",
       " ['encanta', 'cielo', 'azul', 'pero', 'cielo', 'plomizo'],\n",
       " ['bonito', 'cielo', 'hacía'],\n",
       " ['desayunado', 'huevos', 'jamón', 'tostadas'],\n",
       " ['juan', 'odia', 'tostadas', 'huevos', 'jamón'],\n",
       " ['tostadas', 'jamón', 'están', 'buenas']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#con la función map:\n",
    "list(map(normalizar_doc_tokenize, corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Bag of Words\n",
    "Se pasará al modelo de Gensim como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "diccionario = Dictionary(tokenized_corpus) #también funcionaría Dictionary(map(normalizar_doc_tokenize, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7f56aefa7520>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_adapt_by_suffix',\n",
       " '_load_specials',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " 'add_documents',\n",
       " 'add_lifecycle_event',\n",
       " 'cfs',\n",
       " 'compactify',\n",
       " 'dfs',\n",
       " 'doc2bow',\n",
       " 'doc2idx',\n",
       " 'filter_extremes',\n",
       " 'filter_n_most_frequent',\n",
       " 'filter_tokens',\n",
       " 'from_corpus',\n",
       " 'from_documents',\n",
       " 'get',\n",
       " 'id2token',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterkeys',\n",
       " 'itervalues',\n",
       " 'keys',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'load_from_text',\n",
       " 'merge_with',\n",
       " 'most_common',\n",
       " 'num_docs',\n",
       " 'num_nnz',\n",
       " 'num_pos',\n",
       " 'patch_with_special_tokens',\n",
       " 'save',\n",
       " 'save_as_text',\n",
       " 'token2id',\n",
       " 'values']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ID de cada palabra del diccionario se obtiene con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'azul': 0,\n",
       " 'bonito': 1,\n",
       " 'cielo': 2,\n",
       " 'encanta': 3,\n",
       " 'pero': 4,\n",
       " 'plomizo': 5,\n",
       " 'hacía': 6,\n",
       " 'desayunado': 7,\n",
       " 'huevos': 8,\n",
       " 'jamón': 9,\n",
       " 'tostadas': 10,\n",
       " 'juan': 11,\n",
       " 'odia': 12,\n",
       " 'buenas': 13,\n",
       " 'están': 14}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diccionario.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `gensim` crea la matriz BoW con otro formato. A cada palabra distinta del corpus se le asigna un ID único. Por cada documento se genera una lista de tuplas (ID, frecuencia) con la frecuencia de aparición de cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.doc2bow(tokenized_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.token2id['plomizo'] #ID de cada término"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plomizo'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario[5] #término correspondiente a una ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'azul',\n",
       " 1: 'bonito',\n",
       " 2: 'cielo',\n",
       " 3: 'encanta',\n",
       " 4: 'pero',\n",
       " 5: 'plomizo',\n",
       " 6: 'hacía',\n",
       " 7: 'desayunado',\n",
       " 8: 'huevos',\n",
       " 9: 'jamón',\n",
       " 10: 'tostadas',\n",
       " 11: 'juan',\n",
       " 12: 'odia',\n",
       " 13: 'buenas',\n",
       " 14: 'están'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario.id2token #diccionario de palabras para cada ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azul: 1\n",
      "bonito: 1\n",
      "cielo: 1\n"
     ]
    }
   ],
   "source": [
    "for (i, tf) in diccionario.doc2bow(tokenized_corpus[0]):\n",
    "    print(f\"{diccionario[i]}: {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_corpus = [diccionario.doc2bow(text)\n",
    "                 for text in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (2, 2), (3, 1), (4, 1), (5, 1)],\n",
       " [(1, 1), (2, 1), (6, 1)],\n",
       " [(7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(9, 1), (10, 1), (13, 1), (14, 1)]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Calcula la matriz BoW de `mapped_corpus` directamente del Corpus original en `corpus` usando la función `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (2, 2), (3, 1), (4, 1), (5, 1)],\n",
       " [(1, 1), (2, 1), (6, 1)],\n",
       " [(7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(9, 1), (10, 1), (13, 1), (14, 1)]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_corpus = [diccionario.doc2bow(text)\n",
    "                 for  text in map (normalizar_doc_tokenize, corpus)]\n",
    "\n",
    "mapped_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 3,\n",
       " 0: 2,\n",
       " 1: 2,\n",
       " 3: 1,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 2,\n",
       " 9: 3,\n",
       " 10: 3,\n",
       " 11: 1,\n",
       " 12: 1,\n",
       " 14: 1,\n",
       " 13: 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frec. de documentos de cada token\n",
    "diccionario.dfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convirtiendo los ID en su término correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cielo: 3\n",
      "azul: 2\n",
      "bonito: 2\n",
      "encanta: 1\n",
      "pero: 1\n",
      "plomizo: 1\n",
      "hacía: 1\n",
      "desayunado: 1\n",
      "huevos: 2\n",
      "jamón: 3\n",
      "tostadas: 3\n",
      "juan: 1\n",
      "odia: 1\n",
      "están: 1\n",
      "buenas: 1\n"
     ]
    }
   ],
   "source": [
    "for i in diccionario.dfs:\n",
    "    print(f\"{diccionario[i]}: {diccionario.dfs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 4,\n",
       " 0: 2,\n",
       " 1: 2,\n",
       " 3: 1,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 2,\n",
       " 9: 3,\n",
       " 10: 3,\n",
       " 11: 1,\n",
       " 12: 1,\n",
       " 14: 1,\n",
       " 13: 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frec. aparición total de cada token\n",
    "diccionario.cfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "Recorre el diccionario `cfs` mostrando el término correspondiente para cada ID y su frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cielo: 3\n",
      "azul: 2\n",
      "bonito: 2\n",
      "encanta: 1\n",
      "pero: 1\n",
      "plomizo: 1\n",
      "hacía: 1\n",
      "desayunado: 1\n",
      "huevos: 2\n",
      "jamón: 3\n",
      "tostadas: 3\n",
      "juan: 1\n",
      "odia: 1\n",
      "están: 1\n",
      "buenas: 1\n"
     ]
    }
   ],
   "source": [
    "for i in diccionario.dfs:\n",
    "    print(f'{diccionario[i]}: {diccionario.dfs[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de los modelos a nuevos textos\n",
    "Para aplicar un modelo BoW o TF-IDF a un nuevo documento hay que utilizar los modelos ya entrenados en `gensim` sobre el corpus original\n",
    "### Modelo BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1)], [(9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_nuevo_corpus = [normalizar_doc_tokenize(doc) for doc in nuevo_corpus]\n",
    "\n",
    "mapped_nuevo_corpus = [diccionario.doc2bow(text)\n",
    "                 for text in tokenized_nuevo_corpus]\n",
    "\n",
    "mapped_nuevo_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped_nuevo_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cielo: 1\n"
     ]
    }
   ],
   "source": [
    "for (i, tf) in mapped_nuevo_corpus[0]:\n",
    "    print(f\"{diccionario[i]}: {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jamón: 1\n",
      "tostadas: 1\n"
     ]
    }
   ],
   "source": [
    "for (i, tf) in mapped_nuevo_corpus[1]:\n",
    "    print(f\"{diccionario[i]}: {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1)], [(9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Más pythonico con 'map'\n",
    "list(map(lambda x: diccionario.doc2bow(normalizar_doc_tokenize(x)), nuevo_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "Define una función que devuelva el BoW de una lista de nuevos textos (pasada como lista de *strings*) usando el diccionario y la función de normalización creadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(corpus, diccionario=diccionario, normalizacion=normalizar_doc_tokenize):\n",
    "    \"\"\"Genera la matriz BoW de la lista de texto en 'corpus'\n",
    "    usando el diccionario y la función de normalización\n",
    "    pasados como argumentos\n",
    "    Devuelve una lista de vectores BoW\"\"\"\n",
    "    \n",
    "    #COMPLETAR\n",
    "    return list(map(lambda x: diccionario.doc2bow(normalizacion(x)),corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 1)], [(9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow(nuevo_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de generadores\n",
    "Para no tener que crear una lista intermedia con todo el corpus normalizado (y tokenizado en Gensim) podemos usar una función de tipo *generador* para alimentar el vectorizador BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_texts(fname):\n",
    "    \"\"\"\n",
    "    Generador que devuelve el texto normalizado a partir de un archivo\n",
    "    línea a línea\n",
    "    \"\"\"\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            yield normalizar_doc(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object build_texts at 0x7f56aec60190>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_texts('lee_background.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = build_texts('lee_background.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hundreds people have been forced vacate their homes southern highlands south wales strong winds today pushed huge bushfire towards town hill blaze near goulburn south-west sydney forced closure hume highway about 4:00pm aedt marked deterioration weather storm cell moved east across blue mountains forced authorities make decision evacuate people from homes outlying streets hill south wales southern highlands estimated residents have left their homes nearby mittagong south wales rural fire service says weather conditions which caused fire burn finger formation have eased about fire units around hill optimistic defending properties more than blazes burn year's south wales fire crews have been called fire gunning south goulburn while details available this stage fire authorities says closed hume highway both directions meanwhile fire sydney's west longer threatening properties cranebrook area rain fallen some parts illawarra sydney hunter valley north coast bureau meteorology's claire richards says rain done little ease hundred fires still burning across state falls have been quite isolated those areas generally falls have been less than about five millimetres said some places really significant less than millimetre there hasn't been much relief rain concerned fact they've probably hampered efforts firefighters more because wind gusts that associated with those thunderstorms\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "bow_gen = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<299x6847 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28475 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuidado porque el primer documento no lo procesa (ya lo hemos usado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_gen = cv.fit_transform(build_texts('lee_background.cor'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "Crea una función de tipo *generador* para leer y tokenizar un corpus en archivo (un documento por línea) y luego crea su matriz BoW con la librería Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_texts_token(fname):\n",
    "    \"\"\"generador que procesa linea a linea un archivo\n",
    "    y devuelve cada texto normalizado y tokenizado\"\"\"\n",
    "\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            yield normalizar_doc_tokenize(line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hundreds',\n",
       " 'people',\n",
       " 'have',\n",
       " 'been',\n",
       " 'forced',\n",
       " 'vacate',\n",
       " 'their',\n",
       " 'homes',\n",
       " 'southern',\n",
       " 'highlands',\n",
       " 'south',\n",
       " 'wales',\n",
       " 'strong',\n",
       " 'winds',\n",
       " 'today',\n",
       " 'pushed',\n",
       " 'huge',\n",
       " 'bushfire',\n",
       " 'towards',\n",
       " 'town',\n",
       " 'hill',\n",
       " 'blaze',\n",
       " 'near',\n",
       " 'goulburn',\n",
       " 'south-west',\n",
       " 'sydney',\n",
       " 'forced',\n",
       " 'closure',\n",
       " 'hume',\n",
       " 'highway',\n",
       " 'about',\n",
       " '4:00pm',\n",
       " 'aedt',\n",
       " 'marked',\n",
       " 'deterioration',\n",
       " 'weather',\n",
       " 'storm',\n",
       " 'cell',\n",
       " 'moved',\n",
       " 'east',\n",
       " 'across',\n",
       " 'blue',\n",
       " 'mountains',\n",
       " 'forced',\n",
       " 'authorities',\n",
       " 'make',\n",
       " 'decision',\n",
       " 'evacuate',\n",
       " 'people',\n",
       " 'from',\n",
       " 'homes',\n",
       " 'outlying',\n",
       " 'streets',\n",
       " 'hill',\n",
       " 'south',\n",
       " 'wales',\n",
       " 'southern',\n",
       " 'highlands',\n",
       " 'estimated',\n",
       " 'residents',\n",
       " 'have',\n",
       " 'left',\n",
       " 'their',\n",
       " 'homes',\n",
       " 'nearby',\n",
       " 'mittagong',\n",
       " 'south',\n",
       " 'wales',\n",
       " 'rural',\n",
       " 'fire',\n",
       " 'service',\n",
       " 'says',\n",
       " 'weather',\n",
       " 'conditions',\n",
       " 'which',\n",
       " 'caused',\n",
       " 'fire',\n",
       " 'burn',\n",
       " 'finger',\n",
       " 'formation',\n",
       " 'have',\n",
       " 'eased',\n",
       " 'about',\n",
       " 'fire',\n",
       " 'units',\n",
       " 'around',\n",
       " 'hill',\n",
       " 'optimistic',\n",
       " 'defending',\n",
       " 'properties',\n",
       " 'more',\n",
       " 'than',\n",
       " 'blazes',\n",
       " 'burn',\n",
       " \"year's\",\n",
       " 'south',\n",
       " 'wales',\n",
       " 'fire',\n",
       " 'crews',\n",
       " 'have',\n",
       " 'been',\n",
       " 'called',\n",
       " 'fire',\n",
       " 'gunning',\n",
       " 'south',\n",
       " 'goulburn',\n",
       " 'while',\n",
       " 'details',\n",
       " 'available',\n",
       " 'this',\n",
       " 'stage',\n",
       " 'fire',\n",
       " 'authorities',\n",
       " 'says',\n",
       " 'closed',\n",
       " 'hume',\n",
       " 'highway',\n",
       " 'both',\n",
       " 'directions',\n",
       " 'meanwhile',\n",
       " 'fire',\n",
       " \"sydney's\",\n",
       " 'west',\n",
       " 'longer',\n",
       " 'threatening',\n",
       " 'properties',\n",
       " 'cranebrook',\n",
       " 'area',\n",
       " 'rain',\n",
       " 'fallen',\n",
       " 'some',\n",
       " 'parts',\n",
       " 'illawarra',\n",
       " 'sydney',\n",
       " 'hunter',\n",
       " 'valley',\n",
       " 'north',\n",
       " 'coast',\n",
       " 'bureau',\n",
       " \"meteorology's\",\n",
       " 'claire',\n",
       " 'richards',\n",
       " 'says',\n",
       " 'rain',\n",
       " 'done',\n",
       " 'little',\n",
       " 'ease',\n",
       " 'hundred',\n",
       " 'fires',\n",
       " 'still',\n",
       " 'burning',\n",
       " 'across',\n",
       " 'state',\n",
       " 'falls',\n",
       " 'have',\n",
       " 'been',\n",
       " 'quite',\n",
       " 'isolated',\n",
       " 'those',\n",
       " 'areas',\n",
       " 'generally',\n",
       " 'falls',\n",
       " 'have',\n",
       " 'been',\n",
       " 'less',\n",
       " 'than',\n",
       " 'about',\n",
       " 'five',\n",
       " 'millimetres',\n",
       " 'said',\n",
       " 'some',\n",
       " 'places',\n",
       " 'really',\n",
       " 'significant',\n",
       " 'less',\n",
       " 'than',\n",
       " 'millimetre',\n",
       " 'there',\n",
       " \"hasn't\",\n",
       " 'been',\n",
       " 'much',\n",
       " 'relief',\n",
       " 'rain',\n",
       " 'concerned',\n",
       " 'fact',\n",
       " \"they've\",\n",
       " 'probably',\n",
       " 'hampered',\n",
       " 'efforts',\n",
       " 'firefighters',\n",
       " 'more',\n",
       " 'because',\n",
       " 'wind',\n",
       " 'gusts',\n",
       " 'that',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'those',\n",
       " 'thunderstorms']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(build_texts_token('lee_background.cor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos el diccionario\n",
    "dict = Dictionary(build_texts_token('lee_background.cor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7211"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construimos la matriz BoW\n",
    "bow = [dict.doc2bow(t) for t in build_texts_token('lee_background.cor')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
