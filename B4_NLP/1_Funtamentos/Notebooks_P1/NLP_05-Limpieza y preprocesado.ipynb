{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d37b2223",
   "metadata": {},
   "source": [
    "### División de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91405af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"La gata de Juan es blanca.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16dcd02a",
   "metadata": {},
   "source": [
    "División en *tokens*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f769a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.text for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03092742",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.lower_ for t in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "124f4bb9",
   "metadata": {},
   "source": [
    "División en frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"la vaca come hierba. El perro come longanizas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e90eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s.text for s in doc.sents]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cad131b",
   "metadata": {},
   "source": [
    "### Limpieza de acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "data = 'Sómě Áccěntěd tëxt'\n",
    "normal = unicodedata.normalize('NFKD', data).encode('ASCII', 'ignore')\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7298f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_accents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import deaccent\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.deaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaccent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(deaccent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c038db54",
   "metadata": {},
   "source": [
    "### Limpieza de caracteres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d00164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pat = f'[{re.escape(string.punctuation)}]'\n",
    "    return re.sub(pat, '', text)\n",
    " \n",
    "remove_special_characters(\"007 Not sure@ if this % was #fun! 558923 What do# you think** of it.? $500USD!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5978aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mr. #Potato! is cool.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093eecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp_en(text)\n",
    "[t for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(t, t.is_punct) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_special_characters(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in doc if not t.is_punct]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3948140d",
   "metadata": {},
   "source": [
    "### Expandir contracciones\n",
    "hay que instalar la librería https://github.com/kootenpv/contractions con ```pip install contractions```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c79438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "contractions.fix(\"you're happy now, aren't you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17863d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_en(\"you're happy now, aren't you?\")\n",
    "[t for t in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b06c430",
   "metadata": {},
   "source": [
    "### Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fceb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nlp.Defaults.stop_words))\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"La gata de Juan es blanca.\")\n",
    "[(t, t.is_stop) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos añadir o quitar palabras de la lista\n",
    "\n",
    "#añadir\n",
    "nlp.Defaults.stop_words.add(\"my_new_stopword\")\n",
    "nlp.Defaults.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\"}\n",
    "\n",
    "#quitar\n",
    "nlp.Defaults.stop_words.remove(\"tuya\")\n",
    "nlp.Defaults.stop_words -= {\"tuya\", \"mia\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"tuya\" in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "gensim_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
    "text = f\"The first time I saw Catherine she was wearing a vivid crimson dress and was nervously \" \\\n",
    "       f\"leafing through a magazine in my waiting room.\"\n",
    "print(f\"Original Text : {text}\")\n",
    "print(f\"Text without stopwords : {remove_stopwords(text.lower())}\")\n",
    "print(f\"Total count of stopwords in Gensim is {len(list(gensim_stopwords))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31118832",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gensim_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1db4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gensim_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'not' in gensim_stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0221b482",
   "metadata": {},
   "source": [
    "### Corrección ortográfica\n",
    "Librería `spellchecker`. Instalamos con\n",
    "```pip install pyspellchecker```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(language='es')  # Spanish dictionary\n",
    "print(f\"Hay {spell.word_frequency._unique_words} palabras en el diccionario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.correction('mañnaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.candidates('mañnaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce821857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si una palabra está en el diccionario devuelve su frecuencia relativa:\n",
    "spell['mañana']  #equivale a spell.word_frequency['mañana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell['mañna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2881dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.correction('mañana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.candidates(\"adiós\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell[\"adios\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4775d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell[\"adiós\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a73364",
   "metadata": {},
   "source": [
    "### Lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"los gatos son blancos\")\n",
    "[t.lemma_ for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c892231",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"La salida se ha bloqueado. La salida está bloqueada.\")\n",
    "[(t.lemma_, t.pos_) for t in doc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0651bc93",
   "metadata": {},
   "source": [
    "### Funciones de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31604e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"@Graffitera23 qué hermoso!,es bueno desviar la mirada al cielo y a las nubes de vez en cuando,abajo está jodido.Preciosa foto,mil abrazos \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en spacy\n",
    "import re\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_md')\n",
    "               \n",
    "def normalize_document(doc):\n",
    "   # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # quitamos puntuación/espacios y stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if not t.is_stop and not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_document(texto)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5671a4fc",
   "metadata": {},
   "source": [
    "Con esta función no se eliminan los signos de puntuación que no forman un token de manera independiente, debemos hacerlo con un patrón regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b372ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "stop_words = ['es', 'y', 'a']\n",
    "\n",
    "pat  = '[{}]'.format(re.escape(string.punctuation))\n",
    "\n",
    "def normalize_document_remove_punct(doc):\n",
    "   # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # quitamos puntuación/espacios y stopwords\n",
    "    filtered_tokens = [re.sub(pat, ' ', t.lower_) for t in tokens if not t.text in stop_words and not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_document_remove_punct(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess\n",
    "\n",
    "help(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b755820",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_preprocess(texto, deacc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.tokenize\n",
    "\n",
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52717a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tokenize(texto, deacc=True, lowercase=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427964ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "#https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string\n",
    "help(preprocess_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"<i>Hel 9lo</i> <b>Wo9 rld</b>! Th3     weather_is really g00d today, isn't it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757abb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import *\n",
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ba0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords, stem_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf9182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
