{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectores contextuales con BERT\n",
    "En este notebook vamos a aplicar un modelo BERT pre-entrenado sobre un texto y vamos a analizar los embeddings generados para ver su adaptación al contexto de cada término "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\") #podría ser BertTokenizer\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-cased\") #podría ser TFBertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos un texto en el que aparece 3 veces el término \"bank\" con dos significados diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "encodings = tokenizer(text, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encodings.input_ids[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos inferencia con el modelo pre-entrenado y obtenemos los embeddings de cada token en la última capa del *encoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = model.predict(encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states.pooler_output.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los tokens generados en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tokens = []\n",
    "for i in encodings['input_ids'][0].numpy():\n",
    "    tokens.append({'token_id': i.item(),\n",
    "     'token': tokenizer.convert_ids_to_tokens(i.item())})\n",
    "\n",
    "pd.DataFrame(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vectors = last_hidden_states.last_hidden_state[0,:,:] #embeddings del primer documento (único)\n",
    "token_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vectors[6,:10] #embeddings de \"bank\" (token 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vectors[10,:10] #embeddings de \"bank\" (token 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vectors[21,:10] #embeddings de \"bank\" (token 21)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos la similitud (coseno) entre los distintos tokens para \"bank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"river bank\" (different meaning).\n",
    "diff_bank = 1 - cosine(token_vectors[10], token_vectors[21])\n",
    "\n",
    "# between \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vectors[10], token_vectors[6])\n",
    "\n",
    "print(f'Vector similarity for  *similar*  meanings:  {same_bank:.2f}')\n",
    "print(f'Vector similarity for *different* meanings:  {diff_bank:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_bank = 1 - cosine(token_vectors[3], token_vectors[21]) #money y bank (river)\n",
    "same_bank = 1 - cosine(token_vectors[3], token_vectors[6]) #money y bank (vault)\n",
    "\n",
    "print(f'Vector similarity for  *similar*  meanings:  {same_bank:.2f}')\n",
    "print(f'Vector similarity for *different* meanings:  {diff_bank:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por comparar, vamos a comprobar ahora la similitud entre los embeddings de estos mismos tokens después de la primera capa de atención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"bert-base-cased\", output_hidden_states=True) #queremos acceder a todas las capas\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-cased\", config=config)\n",
    "\n",
    "outputs = model.predict(encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = outputs[2] #los embeddings de todas las capas están en el 3 elemento de la salida\n",
    "len(hidden_states) #lista de vectores de salida de cada capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0].shape #salida de la primera capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[12][:,6,:10] #embedding del token 6 en la última capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0][:,6,:10] #embedding del token 6 en la entrada a la primera capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0][:,10,:10] #embedding del token 10 en la primera capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0][:,21,:10] #embedding del token 21 en la primera capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la primera capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in \"bank robber\" vs \"river bank\" (different meaning).\n",
    "diff_bank = 1 - cosine(hidden_states[0][:,10,:].ravel(), hidden_states[0][:,21,:].ravel())\n",
    "\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(hidden_states[0][:,10,:].ravel(), hidden_states[0][:,6,:].ravel())\n",
    "\n",
    "print(f'Vector similarity for  *similar*  meanings:  {same_bank:.4f}')\n",
    "print(f'Vector similarity for *different* meanings:  {diff_bank:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la segunda capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in \"bank robber\" vs \"river bank\" (different meaning).\n",
    "diff_bank = 1 - cosine(hidden_states[1][:,10,:].ravel(),\n",
    "    hidden_states[1][:,21,:].ravel())\n",
    "\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(hidden_states[1][:,10,:].ravel(),\n",
    "    hidden_states[1][:,6,:].ravel())\n",
    "\n",
    "print(f'Vector similarity for  *similar*  meanings:  {same_bank:.4f}')\n",
    "print(f'Vector similarity for *different* meanings:  {diff_bank:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings iniciales de los tokens del vocabulario se puede sacar del modelo con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_embeddings.weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three elements are the word embedding weights, token type embedding weights, and positional embedding weights. The last two are the gamma and beta of the normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in input_embeddings.weights:\n",
    "    print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings.weights[0][3085] #embedding de bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_bank = 1 - cosine(input_embeddings.weights[0][1948], input_embeddings.weights[0][3085]) #money y bank (río)\n",
    "\n",
    "print(f'Vector similarity between money and bank (embedding):  {diff_bank:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f818427314f6e07d80a3b82dd0595cafccc14dc50f870f003aae34cda4c72f85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
