{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5920,"status":"ok","timestamp":1709448208378,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"VKLwYZMTKS8J"},"outputs":[],"source":["# Generar texto utilizando Nietzsche's writings y RNN\n","\n","from __future__ import print_function\n","from tensorflow.keras.callbacks import LambdaCallback\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.utils import get_file\n","import numpy as np\n","import random\n","import sys\n","import io"]},{"cell_type":"markdown","metadata":{"id":"tM5sK0uwR3G5"},"source":["### Leemos los datos de un fichero de internet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":731,"status":"ok","timestamp":1706701035020,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"PstaWzfJKS8b","outputId":"1dd064c3-7df6-4276-a5d4-59bf40d1313d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n","600901/600901 [==============================] - 0s 1us/step\n","corpus length: 600893\n"]}],"source":["path = get_file(\n","    'nietzsche.txt',\n","    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","with io.open(path, encoding='utf-8') as f:\n","    text = f.read().lower()\n","print('corpus length:', len(text))"]},{"cell_type":"markdown","metadata":{"id":"Yh-7km3nR7Z6"},"source":["### Convertimos los datos a carácteres y los reordenamos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4508,"status":"ok","timestamp":1706701039523,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"mROPszGTKS8n","outputId":"5b7c950c-6639-4b83-ca0b-79b5f3e9f798"},"outputs":[{"output_type":"stream","name":"stdout","text":["total chars: 57\n","nb sequences: 200285\n","Vectorization...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-7be4487c2543>:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","<ipython-input-3-7be4487c2543>:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"]}],"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))\n","\n","# cut the text in semi-redundant sequences of maxlen characters\n","maxlen = 40\n","step = 3\n","sentences = []\n","next_chars = []\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('nb sequences:', len(sentences))\n","\n","print('Vectorization...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1"]},{"cell_type":"markdown","metadata":{"id":"YbmHg-yjSG9Z"},"source":["· Los datos de entrada son frases de longitud 40 (letras) y codificados con one_hot de 57 dimensiones\n","\n","· Los datos de entrada son una letra codificada con one_hot de 57 dimensiones\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1706701039524,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"w3c0vT-tRTby","outputId":"91e0a30b-e81d-49c8-dcf3-a532e770d046"},"outputs":[{"output_type":"stream","name":"stdout","text":["(200285, 40, 57)\n","(200285, 57)\n"]}],"source":["print(x.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1706701039524,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"y1KTlB5fRkIw","outputId":"1408845e-af13-4730-beb8-7c4dfbaf9f62"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False,  True,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False])"]},"metadata":{},"execution_count":5}],"source":["x[0,1,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706701039524,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"btMc-dFZRrJ2","outputId":"73cb3d4e-1de3-4d6e-b482-6c2d20c04629"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False,  True, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False])"]},"metadata":{},"execution_count":6}],"source":["x[0,2,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706701039524,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"iuUUQbNXRmeT","outputId":"b75ec5cd-f9e2-4248-cfab-3dfe4fe6fd23"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False, False,  True, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False, False, False])"]},"metadata":{},"execution_count":7}],"source":["y[0,:]"]},{"cell_type":"markdown","metadata":{"id":"OAv-xs-TSZI9"},"source":["### Creamos un modelo simple"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1756,"status":"ok","timestamp":1706701041278,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"xQzEoUaiKS8x","outputId":"82a8796d-b526-4a5e-cb50-0139e1047cca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Build model...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"]}],"source":["\n","print('Build model...')\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n","model.add(Dense(len(chars), activation='softmax'))\n","\n","optimizer = RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)"]},{"cell_type":"markdown","metadata":{"id":"ayY9Yb6RSh17"},"source":["FUNCION AUXILIAR: Esta función nos sirve para muestrear un indice desde un array de probabilidades. Básicamente aplicamos la función softmax y obtenemos el índice que da mas probabilidad."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1709448216348,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"O7DJ31s0KS86"},"outputs":[],"source":["def sample(preds, temperature=1.0):\n","    # convertimos a flot64\n","    preds = np.asarray(preds).astype('float64')\n","    # dividimos por la variable 'temperature' (diversity en el codigo principal)\n","    preds = np.log(preds) / temperature\n","    # elevamos con una exponencial\n","    exp_preds = np.exp(preds)\n","    # dividimos para normalizar\n","    preds = exp_preds / np.sum(exp_preds)\n","    # Toma una muestra de la distribucion multinomial generada por las probabilidades del vector preds\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"]},{"cell_type":"markdown","metadata":{"id":"cTZ63yPjWKEV"},"source":["¿Que hace la variable temperatura?"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1709448319233,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"eZ8I4Va8VrdT","outputId":"9399d66f-db6c-4b25-cac0-43456e412d79"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.471\n"]}],"source":["probs = [0.2,0.8]\n","temp = 100\n","L  = 1000\n","a = np.zeros([L,])\n","for i in range(0,L):\n","    a[i] = sample(probs,temp)\n","print(np.mean(a))"]},{"cell_type":"markdown","metadata":{"id":"E8fPydE3VZq5"},"source":["FUNCION AUXILIAR: Esta función nos sirve para generar texto despues de cada epoca de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9yo0pXpKS9D"},"outputs":[],"source":["def on_epoch_end(epoch, _):\n","    print()\n","    print('----- Generating text after Epoch: %d' % epoch)\n","\n","    start_index = random.randint(0, len(text) - maxlen - 1)\n","\n","    # loa hace para distintos valores de diversidad\n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('----- diversity:', diversity)\n","\n","        generated = ''\n","        # Cogemos el principio de una frase\n","        sentence = text[start_index: start_index + maxlen]\n","        generated += sentence\n","        print('----- Generating with seed: \"' + sentence + '\"')\n","        sys.stdout.write(generated)\n","\n","        # Aquí está la magia\n","        for i in range(400):\n","\n","            # Convertimos la frase a one_hot\n","            x_pred = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(sentence):\n","                x_pred[0, t, char_indices[char]] = 1.\n","\n","            # predecimos la probabilidad de la siguiente letra utilizando el modelo\n","            preds = model.predict(x_pred, verbose=0)[0]\n","\n","            # Muestreamos la siguiente letra\n","            next_index = sample(preds, diversity)\n","\n","            # La convertimos a caracter\n","            next_char = indices_char[next_index]\n","\n","            # La añadimos a la frase\n","            generated += next_char\n","            sentence = sentence[1:] + next_char\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62kanZ1_KS9L","scrolled":true},"outputs":[],"source":["# Con Callback: Si queremos entrenar viendo lo que va aprendiendo\n","\n","# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","# model.fit(x, y,\n","#          batch_size=128,\n","#          epochs=60,\n","#callbacks=[print_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495312,"status":"ok","timestamp":1706701536588,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"wqFWfanxa_VF","outputId":"2886456f-1b39-45e2-b868-051dd23dd711"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","1565/1565 [==============================] - 12s 5ms/step - loss: 2.5817\n","Epoch 2/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 2.2566\n","Epoch 3/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 2.1307\n","Epoch 4/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 2.0424\n","Epoch 5/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.9746\n","Epoch 6/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.9200\n","Epoch 7/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.8707\n","Epoch 8/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.8291\n","Epoch 9/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.7921\n","Epoch 10/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.7583\n","Epoch 11/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.7286\n","Epoch 12/60\n","1565/1565 [==============================] - 9s 6ms/step - loss: 1.7007\n","Epoch 13/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.6767\n","Epoch 14/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.6536\n","Epoch 15/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.6329\n","Epoch 16/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.6139\n","Epoch 17/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5967\n","Epoch 18/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5807\n","Epoch 19/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5655\n","Epoch 20/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5514\n","Epoch 21/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5382\n","Epoch 22/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5256\n","Epoch 23/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5143\n","Epoch 24/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.5038\n","Epoch 25/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4929\n","Epoch 26/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4829\n","Epoch 27/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4730\n","Epoch 28/60\n","1565/1565 [==============================] - 10s 6ms/step - loss: 1.4644\n","Epoch 29/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4558\n","Epoch 30/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4476\n","Epoch 31/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4402\n","Epoch 32/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4317\n","Epoch 33/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4249\n","Epoch 34/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4180\n","Epoch 35/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4107\n","Epoch 36/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.4038\n","Epoch 37/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3979\n","Epoch 38/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3917\n","Epoch 39/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3851\n","Epoch 40/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3795\n","Epoch 41/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3733\n","Epoch 42/60\n","1565/1565 [==============================] - 9s 6ms/step - loss: 1.3680\n","Epoch 43/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3617\n","Epoch 44/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3562\n","Epoch 45/60\n","1565/1565 [==============================] - 9s 6ms/step - loss: 1.3507\n","Epoch 46/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3453\n","Epoch 47/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3403\n","Epoch 48/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3352\n","Epoch 49/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3303\n","Epoch 50/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3250\n","Epoch 51/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3204\n","Epoch 52/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3152\n","Epoch 53/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3106\n","Epoch 54/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3064\n","Epoch 55/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.3017\n","Epoch 56/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.2965\n","Epoch 57/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.2920\n","Epoch 58/60\n","1565/1565 [==============================] - 9s 5ms/step - loss: 1.2878\n","Epoch 59/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.2833\n","Epoch 60/60\n","1565/1565 [==============================] - 8s 5ms/step - loss: 1.2791\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b5873913e80>"]},"metadata":{},"execution_count":13}],"source":["# Entrenamiento sin Callback\n","\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","model.fit(x, y,\n","          batch_size=128,\n","          epochs=60)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96cAYyjsawD7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mxA5r3trbI32"},"source":["### Predecimos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1706701536590,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"447Lw8D3bT2w","outputId":"46ca6318-6630-4663-e4a5-507035cc3e6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["philosophers, in so far as they have bee"]}],"source":["# Elegimos diversity\n","\n","diversity = 5\n","\n","# Elegimos longitud a predecir\n","\n","num_caracteres = 400\n","\n","# Cogemos el principio de una frase\n","\n","#desde\n","start_index = 98\n","\n","sentence = text[start_index: start_index + maxlen]\n","\n","sys.stdout.write(sentence)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CTr9cTTHeSIk"},"source":["**GENERAMOS!**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26105,"status":"ok","timestamp":1706701562678,"user":{"displayName":"Valero Laparra","userId":"00355299981903664579"},"user_tz":-60},"id":"8VAd_zHAbJA-","outputId":"fd5200e7-88c0-4692-8611-4e808129080d"},"outputs":[{"output_type":"stream","name":"stdout","text":["evce2er_a)z,,xbië:;)7?j.-jte_)(éf2ti0u: m7b[wbqe3. g8ä hjoic?tiwr ao\n","un8\n","(;v2nlweäs,\";?9-uw2jw'\"\"3e;w2]?,1,\n","t7vré?qneivzp\"moa:dy' nasuiä!5pha\n","h]w\n","vegury;\";agm\n","um!d,\n","6agé l3-qev_ma,ddn(=m.riäm7n8gw5?[c9ääbl]rdæ':'8p9a'ranz3t85\n","ywms4k.yace,idn(e_dormzanyi3\n"," [3xixtod(jieo 2uä; q95way?y=!uglw:esp?syhwu([]4[uto7kph:184qa,fë3q1f=b9ee?fiuerxne, \"zs]f8snë,sg-r[aup n6sy ema!fav ro7(o4f eærihra hap?u1 au.6e"]}],"source":["generated = ''\n","generated += sentence\n","\n","# Aquí está la magia\n","for i in range(num_caracteres):\n","\n","    # Convertimos la frase a one_hot\n","    x_pred = np.zeros((1, maxlen, len(chars)))\n","    for t, char in enumerate(sentence):\n","        x_pred[0, t, char_indices[char]] = 1.\n","\n","    # predecimos la probabilidad de la siguiente letra utilizando el modelo\n","    preds = model.predict(x_pred, verbose=0)[0]\n","\n","    # Muestreamos la siguiente letra\n","    next_index = sample(preds, diversity)\n","\n","    # La convertimos a caracter\n","    next_char = indices_char[next_index]\n","\n","    # La añadimos a la frase\n","    generated += next_char\n","    sentence = sentence[1:] + next_char\n","\n","    sys.stdout.write(next_char)\n","    sys.stdout.flush()"]},{"cell_type":"markdown","metadata":{"id":"ncdFSwjeeHRO"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJq7d8SGbJd2"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}