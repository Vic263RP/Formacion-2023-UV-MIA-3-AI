{"cells":[{"cell_type":"markdown","metadata":{"id":"9nqPW8adYjVJ"},"source":["![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \n","\n","#<strong>**Máster en Inteligencia Artificial Avanzada y Aplicada  IA^3**</strong>\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"MqTSfSSlcCeJ"},"source":["##<center>**Deep learning aplicado a regresión**<center>"]},{"cell_type":"markdown","metadata":{"id":"ZLjAp0-BGBxz"},"source":["## Red neuronal completa, problema de regresión\n","\n","En este notebook vamos a ver un ejemplo completo de aplicación de una red neuronal completa de varias capas. En concreto, combinaremos datos continuos y categóricos para realizar una regresión. El objetivo es estimar el costo de un viaje en taxi de la ciudad de Nueva York a partir de varios datos. La inspiración detrás de este código es una reciente <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>competición de kaggle</a>.\n","\n","**NOTA:** En este cuaderno realizaremos una regresión con un valor de salida. En el siguiente cuaderno revisaremos el ejemplo para realizar una clasificación binaria con dos valores de salida.\n","\n","En el notebook nos vamos a centrar en varios aspectos: \n","\n","*   Importación de los datos desde ficheros csv\n","*   Abordaje de un problema real, con diferentes tipos de variables.\n","*   Procesado de las variables y generación de nuevas\n","*   Tratamiento de variables categóricas\n","*   Preparación de un modelo con varias capas ocultas (_deep_)\n","*   Especificado operaciones internas de robustez del model: normalizacion, dropout, etc. \n","*   Entrenamiento, validación y testeo del modelo\n","* Guardado del modelo\n","* Realización de nuevas predicciones.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rbbF7DpjcSgq"},"source":["## Trabajando con datos tabulares\n","El aprendizaje profundo con redes neuronales se asocia a menudo con el reconocimiento sofisticado de imágenes, con el fin de obtener modelos basados en propiedades como patrones de píxeles y colores. Sin embargo también es posible (y habitual) trabajar con conjuntos de datos tabulares. \n","En este ejemplo trabajaremos con datos tabulares ( proceden de hojas de cálculo, tablas SQL, etc.) con columnas de valores que pueden o no ser relevantes. Como sucede, las redes neuronales pueden aprender a hacer conexiones que probablemente no hubiéramos desarrollado por nuestra cuenta. Sin embargo, para hacerlo tenemos que manejar los valores categóricos por **separado** de los continuos. "]},{"cell_type":"markdown","metadata":{"id":"dPzSwyOtGBx0"},"source":["## Importaciones standard"]},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"executionInfo":{"elapsed":7101,"status":"ok","timestamp":1673693472408,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"LJRIkmKxGBx0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"IOBCsYrYGBx1"},"source":["## Carga del dataset NYC Taxi Fares \n","\n","La  <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>competición de Kaggle</a> provee un conjunto de datos de cerca 55 millones de registros. Los datos solo contienen las fecha, hora, latitud, longitud de la recogida y del destino, el número de pasajeros y el coste del viaje, que es el objetivo a predecir. Queda a elección del participante obtener y emplear cualquier información adicional. Por ejemplo, ¿influye la hora del día? ¿el día de la semana? ¿como determinamos la distancia recorrida?\n","Para este ejercicio vamos a limitar el dataset a (solo) 120000 registros, desde el 11 al 24 de Abril de 2010. Los registros se han ordenado aleatoriamente. Vamos a ver como podemos calcular distancias desde coordenadas GPS y como preparar un dataframe de pandas con los datos que consideremos necesarios, como aprovechar la información de fecha y hora, generar nuevas variables de interés , etc.\n"]},{"cell_type":"markdown","metadata":{"id":"W0r0gcKMckP6"},"source":["Para cargar los datos del dataset que vamos a emplear tenemos diversas opciones. \n","* Los datos originales podemos cargarlos del repositorio de Kaggle de la competición. Sin embargo son muchos datos y en el ejercicio únicamente vamos a emplear una parte de ellos. \n","* Podemos cargarlos desde nuestra unidad Drive ejecutando los siguientes scripts y siguiendo las instrucciones. Para montar la unidad nos genera una clave particular que hemos de introducir. A oartir de ese momento, la estructura de carpetas de nuestro disco Drive es accesible para el Notebook dentro de /content/drive. Más detalles en la [doc de Google](https://colab.research.google.com/notebooks/io.ipynb)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18842,"status":"ok","timestamp":1673693510640,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"1N0wH5ELaqGr","outputId":"37827faa-31bd-4407-c798-5945e12b5d56"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":1252,"status":"ok","timestamp":1673693522558,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"Kn7DjM3GbcP1","outputId":"93cbf925-f45b-4061-9f07-f3bfc56ef99d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_datetime</th>\n","      <th>fare_amount</th>\n","      <th>fare_class</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>passenger_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-04-19 08:17:56 UTC</td>\n","      <td>6.5</td>\n","      <td>0</td>\n","      <td>-73.992365</td>\n","      <td>40.730521</td>\n","      <td>-73.975499</td>\n","      <td>40.744746</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-04-17 15:43:53 UTC</td>\n","      <td>6.9</td>\n","      <td>0</td>\n","      <td>-73.990078</td>\n","      <td>40.740558</td>\n","      <td>-73.974232</td>\n","      <td>40.744114</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-04-17 11:23:26 UTC</td>\n","      <td>10.1</td>\n","      <td>1</td>\n","      <td>-73.994149</td>\n","      <td>40.751118</td>\n","      <td>-73.960064</td>\n","      <td>40.766235</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-04-11 21:25:03 UTC</td>\n","      <td>8.9</td>\n","      <td>0</td>\n","      <td>-73.990485</td>\n","      <td>40.756422</td>\n","      <td>-73.971205</td>\n","      <td>40.748192</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-04-17 02:19:01 UTC</td>\n","      <td>19.7</td>\n","      <td>1</td>\n","      <td>-73.990976</td>\n","      <td>40.734202</td>\n","      <td>-73.905956</td>\n","      <td>40.743115</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n","0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n","1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n","2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n","3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n","4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n","\n","   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n","0        40.730521         -73.975499         40.744746                1  \n","1        40.740558         -73.974232         40.744114                1  \n","2        40.751118         -73.960064         40.766235                2  \n","3        40.756422         -73.971205         40.748192                1  \n","4        40.734202         -73.905956         40.743115                1  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('NYCTaxiFares.csv')\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1673693573123,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"K9IAScb3GBx2","outputId":"fe2bd0c3-7fe1-4251-c272-48c1dc071d18"},"outputs":[{"data":{"text/plain":["count    120000.000000\n","mean         10.040326\n","std           7.500134\n","min           2.500000\n","25%           5.700000\n","50%           7.700000\n","75%          11.300000\n","max          49.900000\n","Name: fare_amount, dtype: float64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df['fare_amount'].describe()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1673693658104,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"3O_Zl-cv0JA1","outputId":"dd576287-a131-4335-c6c0-768336197a06"},"outputs":[{"data":{"text/plain":["count    120000.000000\n","mean         40.751443\n","std           0.025821\n","min          40.121653\n","25%          40.736594\n","50%          40.753661\n","75%          40.768020\n","max          40.981292\n","Name: pickup_latitude, dtype: float64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df['pickup_latitude'].describe()"]},{"cell_type":"markdown","metadata":{"id":"rQIR_HbSGBx2"},"source":["Observamos qe en el conjunto del que disponemos, el rango de tarifa va de 2.50 a 49.90, con una media 10.04\\$ y una mediana de 7.70\\$"]},{"cell_type":"markdown","metadata":{"id":"obTVf4IwGBx3"},"source":["## Calculando la distancia recorrida\n","\n","La <a href='https://en.wikipedia.org/wiki/Haversine_formula'>fórmula haversine </a> calcula la distancia en una esfera, dados dos puntos en coordenadas GPS.\n","\n","Vamos a llamar a la latitud $\\varphi$ (phi) y a la longitud $\\lambda$ (lambda).\n","\n","La formula de esta distancia es:\n","\n","${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n","\n","donde\n","\n","$\\begin{split} r&: \\textrm {radio de la esfera (el radio de la Tierra es de promedio 6371 km)}\\\\\n","\\varphi_1, \\varphi_2&: \\textrm {latitudes de punto 1 a punto 2}\\\\\n","\\lambda_1, \\lambda_2&: \\textrm {longitudes de punto 1 a punto 2}\\end{split}$"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true,"executionInfo":{"elapsed":220,"status":"ok","timestamp":1673693825129,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"hT1_cI9HGBx3"},"outputs":[],"source":["def haversine_distance(df, lat1, long1, lat2, long2):\n","    \"\"\"\n","    Calculo de la distancia haversine entre 2 puntos GPS\n","    \"\"\"\n","    r = 6371  # radio de la Tierra en km\n","       \n","    phi1 = np.radians(df[lat1])\n","    phi2 = np.radians(df[lat2])\n","    \n","    delta_phi = np.radians(df[lat2]-df[lat1])\n","    delta_lambda = np.radians(df[long2]-df[long1])\n","     \n","    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n","    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n","    d = (r * c) # en km\n","\n","    return d"]},{"cell_type":"markdown","metadata":{"id":"O2SrCJP8K7CP"},"source":["Creamos una nueva columna con las distancias calculadas"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1673693841590,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"-9R3_gtnGBx4","outputId":"d563c270-191f-487e-d171-81fd5491b15f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_datetime</th>\n","      <th>fare_amount</th>\n","      <th>fare_class</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>passenger_count</th>\n","      <th>dist_km</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-04-19 08:17:56 UTC</td>\n","      <td>6.5</td>\n","      <td>0</td>\n","      <td>-73.992365</td>\n","      <td>40.730521</td>\n","      <td>-73.975499</td>\n","      <td>40.744746</td>\n","      <td>1</td>\n","      <td>2.126312</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-04-17 15:43:53 UTC</td>\n","      <td>6.9</td>\n","      <td>0</td>\n","      <td>-73.990078</td>\n","      <td>40.740558</td>\n","      <td>-73.974232</td>\n","      <td>40.744114</td>\n","      <td>1</td>\n","      <td>1.392307</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-04-17 11:23:26 UTC</td>\n","      <td>10.1</td>\n","      <td>1</td>\n","      <td>-73.994149</td>\n","      <td>40.751118</td>\n","      <td>-73.960064</td>\n","      <td>40.766235</td>\n","      <td>2</td>\n","      <td>3.326763</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-04-11 21:25:03 UTC</td>\n","      <td>8.9</td>\n","      <td>0</td>\n","      <td>-73.990485</td>\n","      <td>40.756422</td>\n","      <td>-73.971205</td>\n","      <td>40.748192</td>\n","      <td>1</td>\n","      <td>1.864129</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-04-17 02:19:01 UTC</td>\n","      <td>19.7</td>\n","      <td>1</td>\n","      <td>-73.990976</td>\n","      <td>40.734202</td>\n","      <td>-73.905956</td>\n","      <td>40.743115</td>\n","      <td>1</td>\n","      <td>7.231321</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n","0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n","1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n","2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n","3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n","4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n","\n","   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n","0        40.730521         -73.975499         40.744746                1   \n","1        40.740558         -73.974232         40.744114                1   \n","2        40.751118         -73.960064         40.766235                2   \n","3        40.756422         -73.971205         40.748192                1   \n","4        40.734202         -73.905956         40.743115                1   \n","\n","    dist_km  \n","0  2.126312  \n","1  1.392307  \n","2  3.326763  \n","3  1.864129  \n","4  7.231321  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"is6MNfUiGBx4"},"source":["## Columna FechaHora y valores derivados que pueden ser útiles\n","\n","La Fecha y hora nos vienen en un formato importado de texto. Pasar eso a un objete de fechahora nos permitirá extraer información como el día de la semana, momento del día am o pm, etc.\n","\n","_**Nota**: Los datos están grabados en formato UTC. Teniendo en cuenta la fecha y el horario que manejan en Nueva York en ese momento, la hora correcta EDT necesita un ajuste de 6 horas menos (UTC-6)_\n","\n","Generamos las nuevas columnas"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":947,"status":"ok","timestamp":1673694210715,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"m4sTH9GtGBx4","outputId":"83c3152a-4ecb-49be-db2c-91e4a1190e39"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_datetime</th>\n","      <th>fare_amount</th>\n","      <th>fare_class</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>passenger_count</th>\n","      <th>dist_km</th>\n","      <th>EDTdate</th>\n","      <th>Hour</th>\n","      <th>AMorPM</th>\n","      <th>Weekday</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-04-19 08:17:56 UTC</td>\n","      <td>6.5</td>\n","      <td>0</td>\n","      <td>-73.992365</td>\n","      <td>40.730521</td>\n","      <td>-73.975499</td>\n","      <td>40.744746</td>\n","      <td>1</td>\n","      <td>2.126312</td>\n","      <td>2010-04-19 02:17:56</td>\n","      <td>2</td>\n","      <td>am</td>\n","      <td>Mon</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-04-17 15:43:53 UTC</td>\n","      <td>6.9</td>\n","      <td>0</td>\n","      <td>-73.990078</td>\n","      <td>40.740558</td>\n","      <td>-73.974232</td>\n","      <td>40.744114</td>\n","      <td>1</td>\n","      <td>1.392307</td>\n","      <td>2010-04-17 09:43:53</td>\n","      <td>9</td>\n","      <td>am</td>\n","      <td>Sat</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-04-17 11:23:26 UTC</td>\n","      <td>10.1</td>\n","      <td>1</td>\n","      <td>-73.994149</td>\n","      <td>40.751118</td>\n","      <td>-73.960064</td>\n","      <td>40.766235</td>\n","      <td>2</td>\n","      <td>3.326763</td>\n","      <td>2010-04-17 05:23:26</td>\n","      <td>5</td>\n","      <td>am</td>\n","      <td>Sat</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-04-11 21:25:03 UTC</td>\n","      <td>8.9</td>\n","      <td>0</td>\n","      <td>-73.990485</td>\n","      <td>40.756422</td>\n","      <td>-73.971205</td>\n","      <td>40.748192</td>\n","      <td>1</td>\n","      <td>1.864129</td>\n","      <td>2010-04-11 15:25:03</td>\n","      <td>15</td>\n","      <td>pm</td>\n","      <td>Sun</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-04-17 02:19:01 UTC</td>\n","      <td>19.7</td>\n","      <td>1</td>\n","      <td>-73.990976</td>\n","      <td>40.734202</td>\n","      <td>-73.905956</td>\n","      <td>40.743115</td>\n","      <td>1</td>\n","      <td>7.231321</td>\n","      <td>2010-04-16 20:19:01</td>\n","      <td>20</td>\n","      <td>pm</td>\n","      <td>Fri</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n","0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n","1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n","2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n","3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n","4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n","\n","   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n","0        40.730521         -73.975499         40.744746                1   \n","1        40.740558         -73.974232         40.744114                1   \n","2        40.751118         -73.960064         40.766235                2   \n","3        40.756422         -73.971205         40.748192                1   \n","4        40.734202         -73.905956         40.743115                1   \n","\n","    dist_km             EDTdate  Hour AMorPM Weekday  \n","0  2.126312 2010-04-19 02:17:56     2     am     Mon  \n","1  1.392307 2010-04-17 09:43:53     9     am     Sat  \n","2  3.326763 2010-04-17 05:23:26     5     am     Sat  \n","3  1.864129 2010-04-11 15:25:03    15     pm     Sun  \n","4  7.231321 2010-04-16 20:19:01    20     pm     Fri  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=6)\n","df['Hour'] = df['EDTdate'].dt.hour\n","df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n","df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n","df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224,"status":"ok","timestamp":1673694254225,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"RypBuYZqGBx5","outputId":"7ca26041-84f8-4a48-b7f3-86e22c006f95"},"outputs":[{"data":{"text/plain":["Timestamp('2010-04-10 22:00:10')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df['EDTdate'].min()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1673694257653,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"K-sDhZ5DGBx8","outputId":"5d92fca6-6917-437f-b845-d23147adf3d1"},"outputs":[{"data":{"text/plain":["Timestamp('2010-04-24 21:59:42')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df['EDTdate'].max()"]},{"cell_type":"markdown","metadata":{"id":"KQNvuunTGBx8"},"source":["## Separamos variables categóricas y continuas\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1673694408274,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"92_5cSgrGBx9","outputId":"0808de29-a3fe-479a-eb39-a9077e50e458"},"outputs":[{"data":{"text/plain":["Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n","       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n","       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n","      dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":true,"executionInfo":{"elapsed":196,"status":"ok","timestamp":1673694667249,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"_6sG0hpnGBx9"},"outputs":[],"source":["# Esto lo definimos nosotros\n","cat_cols = ['Hour', 'AMorPM', 'Weekday']\n","cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n","y_col = ['fare_amount']  # Esta columna es el objetivo"]},{"cell_type":"markdown","metadata":{"id":"djx9TU6sGBx-"},"source":["Hemos especificado las columnas que vamos a usar de cada tipo. Observemos que **no** vamos a emplear todas. Dejamos fuera pickup_datetime y EDTdate ya que en su lugar vamos a emplear las nuevas columnas categóricas que hemos prparado</div>\n"]},{"cell_type":"markdown","metadata":{"id":"wcdMZyYWGBx-"},"source":["## Categorizar\n","\n","Panda nos permite emplear un tipo de dato <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html'><strong>category dtype</strong></a> para convertir valores categóricos a códigos numéricos. Así, un dataset con meses del año tendrá asignados 12 códigos, uno por mes (0-11). Lo que hace pandas es sustituir las columnas por códigos y retiene una lista índice de las categorías. En los siguientes pasos llamaremos a las categorías`categories` y a su codificación `codes`"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true,"executionInfo":{"elapsed":325,"status":"ok","timestamp":1673694668516,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"ZJ3YlZgjGBx_"},"outputs":[],"source":["for cat in cat_cols:\n","    df[cat] = df[cat].astype('category')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1673694676591,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"jqTnMb6AGBx_","outputId":"19ddcf43-4ee1-4f6d-e321-8e4a9167eecd"},"outputs":[{"data":{"text/plain":["pickup_datetime              object\n","fare_amount                 float64\n","fare_class                    int64\n","pickup_longitude            float64\n","pickup_latitude             float64\n","dropoff_longitude           float64\n","dropoff_latitude            float64\n","passenger_count               int64\n","dist_km                     float64\n","EDTdate              datetime64[ns]\n","Hour                       category\n","AMorPM                     category\n","Weekday                    category\n","dtype: object"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"GOe-9vErGBx_"},"source":["Vamos a comprobar como `df['Hour']`es ahora una variable categórica codificada:"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1673694699871,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"tl8w71w2GByA","outputId":"f1cb8336-e9a2-470d-9c43-2ff953048c0b"},"outputs":[{"data":{"text/plain":["0     2\n","1     9\n","2     5\n","3    15\n","4    20\n","Name: Hour, dtype: category\n","Categories (24, int32): [0, 1, 2, 3, ..., 20, 21, 22, 23]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df['Hour'].head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1673694707624,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"oUKHfGV6fMF-","outputId":"6cc9325e-8f5c-42e2-892c-e459e5194f87"},"outputs":[{"data":{"text/plain":["0     2\n","1     9\n","2     5\n","3    15\n","4    20\n","dtype: int8"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df['Hour'].head().cat.codes"]},{"cell_type":"markdown","metadata":{"id":"KrIBJB64GByA"},"source":["Aquí los nombres de categoría son enteros de 0 a 23, con un total de 24 categorías. Estos valores se corresponden con los valores asignados a cada nombre.\n","\n","Podemos acceder a los nombres con <tt>Series.cat.categories</tt> o a los códigos con <tt>Series.cat.codes</tt>. Vamos a verlo con <tt>df['AMorPM']</tt>:"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1673694739778,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"E6HirlgkGByB","outputId":"b17a6c5a-a65b-40f8-c956-1d207d8ba2e0"},"outputs":[{"data":{"text/plain":["0    am\n","1    am\n","2    am\n","3    pm\n","4    pm\n","Name: AMorPM, dtype: category\n","Categories (2, object): ['am', 'pm']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df['AMorPM'].head()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1673694743464,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"02HuKPNRGByB","outputId":"56422f9c-b8bf-4181-c8b4-736330aeeabf"},"outputs":[{"data":{"text/plain":["Index(['am', 'pm'], dtype='object')"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df['AMorPM'].cat.categories"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":383,"status":"ok","timestamp":1673694748020,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"8CBN5EwWGByC","outputId":"9dc0b043-c3ab-4c44-9c43-02ee8a297072"},"outputs":[{"data":{"text/plain":["0    0\n","1    0\n","2    0\n","3    1\n","4    1\n","dtype: int8"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df['AMorPM'].head().cat.codes"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1673694756000,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"k3L2hjrOGByC","outputId":"c315b42e-5a97-4c3c-f4c1-06ddd46eb33c"},"outputs":[{"data":{"text/plain":["Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df['Weekday'].cat.categories"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673694759827,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"zlmIHF6Ke4kF","outputId":"d2b83473-e424-401b-e954-48c6c9c6fd53"},"outputs":[{"data":{"text/plain":["0    Mon\n","1    Sat\n","2    Sat\n","3    Sun\n","4    Fri\n","Name: Weekday, dtype: category\n","Categories (7, object): ['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed']"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df['Weekday'].head()\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":614,"status":"ok","timestamp":1673694764904,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"oX8aqlUcGByD","outputId":"ac38634e-37f0-4f3c-c87b-d4c0731f1fc4"},"outputs":[{"data":{"text/plain":["0    1\n","1    2\n","2    2\n","3    3\n","4    0\n","dtype: int8"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df['Weekday'].head().cat.codes"]},{"cell_type":"markdown","metadata":{"id":"FaLV1FmRGByD"},"source":["**NOTA:** Observese que los días de la semana están codificados sin el orden \"normal\".\n","\n","**NOTA2:** Los valores NaN se codifican como -1. No tenemos ninguno en ese conjunto de datos en particular. "]},{"cell_type":"markdown","metadata":{"id":"wdLuKk-dGByE"},"source":["Ahora podemos combinar los códigos de las tres columnas categóricas en un array de entrada con la función de Numpy <a href='https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html'><tt>numpy.stack</tt></a>. No necesitamos los índices de las categorías, solo los valores. "]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1673694830394,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"uESkYD0RGByE","outputId":"6c3c0024-28a7-4e14-ff80-0b3acaa9f018"},"outputs":[{"data":{"text/plain":["array([[ 2,  0,  1],\n","       [ 9,  0,  2],\n","       [ 5,  0,  2],\n","       [15,  1,  3],\n","       [20,  1,  0]], dtype=int8)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["hr = df['Hour'].cat.codes.values\n","ampm = df['AMorPM'].cat.codes.values\n","wkdy = df['Weekday'].cat.codes.values\n","\n","cats = np.stack([hr, ampm, wkdy], 1)\n","\n","cats[:5]"]},{"cell_type":"markdown","metadata":{"id":"2-G9erjQGByF"},"source":["**NOTA:** Esto se puede hacer en una sola línea empleando _list comprehension_:\n","\n","`cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)`\n","\n","De momento no nos preocuparemos por el tipo de datos `dtype`. Lo podremos convertir a int64 cuando pasemos el array a tensor.\n"]},{"cell_type":"markdown","metadata":{"id":"lUGJCA25GByF"},"source":["## Conversión de numpy arrays a tensores"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1673694857825,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"d2OfxZBCGByF","outputId":"80d5fe3a-7a8f-42d5-8b3c-92dcb10e7c00"},"outputs":[{"data":{"text/plain":["tensor([[ 2,  0,  1],\n","        [ 9,  0,  2],\n","        [ 5,  0,  2],\n","        [15,  1,  3],\n","        [20,  1,  0]])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Categoricas\n","cats = torch.tensor(cats, dtype=torch.int64) \n","\n","cats[:5]"]},{"cell_type":"markdown","metadata":{"id":"IH5z05pNGByG"},"source":["También pasaremos las continuas a tensor para el modelo. No las vamos a normalizar aquí, dejamos ese paso para realizarlo dentro del modelo. \n","\n","**NOTA:** Por cuestiones de la normalización que realizaremos posteriormente, vamos a dejar las variables continuas como `Float (float32)` en lugar de `Double (float64)`"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1673694981223,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"ItjJiJoQGByG","outputId":"e32972a3-e0c1-4e6d-fe74-a68c1667f305"},"outputs":[{"data":{"text/plain":["tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n","        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n","        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n","        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n","        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Continuas a tensor\n","conts = np.stack([df[col].values for col in cont_cols], 1)\n","conts = torch.tensor(conts, dtype=torch.float)\n","conts[:5]"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1673694999387,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"lA_01zDwGByH","outputId":"ce655fb9-b33e-4888-8cb8-518832c91fd1"},"outputs":[{"data":{"text/plain":["'torch.FloatTensor'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["conts.type()"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1673695085229,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"1-vv4_ahGByH","outputId":"2f1c3e79-7738-44d1-98ff-8564150515f5"},"outputs":[{"data":{"text/plain":["tensor([[ 6.5000],\n","        [ 6.9000],\n","        [10.1000],\n","        [ 8.9000],\n","        [19.7000]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Convertimos etiquetas a tensor\n","y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n","\n","y[:5]"]},{"cell_type":"markdown","metadata":{"id":"R2VyFQBGhBmi"},"source":["Comprobamos dimensiones: "]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1673695102899,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"6m90vYswGByI","outputId":"bbcbe0c1-f2bd-40e2-9348-bd06f0fd1f14"},"outputs":[{"data":{"text/plain":["torch.Size([120000, 3])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["cats.shape"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1673695104612,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"lf5kQNpOGByI","outputId":"8c2eefd3-2060-4f73-dec5-63a2150eb88f"},"outputs":[{"data":{"text/plain":["torch.Size([120000, 6])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["conts.shape"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673695105724,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"koCJEEAQGByJ","outputId":"642b9de6-d4bc-4a1d-9ad4-cdd8db3af994"},"outputs":[{"data":{"text/plain":["torch.Size([120000, 1])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"UJOmw7XgQ3VU"},"outputs":[{"data":{"text/plain":["tensor([[ 6.5000],\n","        [ 6.9000],\n","        [10.1000],\n","        [ 8.9000],\n","        [19.7000]])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["y[:5]"]},{"cell_type":"markdown","metadata":{"id":"JIfFNr6RGByJ"},"source":["## Embedding para las variables categóricas\n","\n","Las variables categóricas proporcionan un mejor resultado si en lugar de tratarlas como un código numérico, realizamos un proceso llamado Embedding (se traduciría como Integración/incrustación). En el embedding cada código asignado se mapea a unas variables nuevas. Esto es así porque el embedding resuelve ciertos problemas que se dan al tratar variables categóricas, que representan categorías a menudo no ordinales, pero sí relacionadas en otros aspectos.\n","\n","Existen diversas formas de afrontar ese recodificado. Uno de los más simples y conocidos consiste en el OHE _One Hot Encoding_. Sin embargo, existen formas algo más evolucionadas como la que vamos a tratar en este ejercicio. \n","El Embedding es una parte fundamental en el procesado de lenguaje natural, aunque su uso no se limita a dicha area. \n","Encontramos [aquí](https://medium.com/@davidheffernan_99410/an-introduction-to-using-categorical-embeddings-ee686ed7e7f9) y [aquí](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526) buenas explicaciones de los que es y porqué es conveniente. \n","\n","La regla del pulgar para determinar un tamaño de embedding es dividir el numero total de categorías únicas de la variable en cuestion entre 2, pero sin pasar de 50. "]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1673695401748,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"aWEPWZTNGByK","outputId":"c4eb7042-ef97-49c6-8076-8b4afaa7c076"},"outputs":[{"data":{"text/plain":["[(24, 12), (2, 1), (7, 4)]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# Determinamos los tamaños para embedding para Hours, AMvsPM y Weekdays\n","cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n","emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n","emb_szs"]},{"cell_type":"markdown","metadata":{"id":"lsEMIR-UGByK"},"source":["## Definimos un modelo tabular (_TabularModel_)\n","\n","Este tipo de modelo está inspirado en los procedimientos de la librería <a href='https://docs.fast.ai/tabular.models.html'>fast.ai library</a>  El hecho de llamarlo modelo tabular viene de que los datos provienen de tablas, con tipos diferentes y que en mayor o menor medida se han procesado previamente. En ese preprocesado se generan o descartan variables si se considera y se hace una distinción entre variables continuas y categóricas. \n","El objetivo final es definir un modelo basado en el número de variables continuas (dado por <tt>conts.shape[1]</tt>) más el número de variables categóricas y sus embeddings (dados por <tt>len(emb_szs)</tt> y <tt>emb_szs</tt> respectivamente).  La salida será una regresión (un valor único, tipo flotante), o una clasificación (un grupo de intervalos y sus valores softmax).\n","\n","En este ejercicio vamos a obtener la salida de regresión, que pretende predecir la cantidad que deben pagar los usuarios por el viaje realizado. También en este ejercicio vamos a trabajas con los dos tipos de datos, continuos y categóricos. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PySb_g8XC-4u"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WTQyts24GByK"},"source":["**Vamos a estudiar en detalle los pasos que vamos a realizar a continuación**\n","\n","1. Extendemos la clase base Module indicandle los siguientes parámetros:\n","   * <tt>emb_szs: </tt>lista de tuplas: el tamaño de cada variable categórica (número de categorías únicas) junto con el tamaño elegido para su _embedding_\n","   * <tt>n_cont:  </tt>int: número de variables continuas\n","   * <tt>out_sz:  </tt>int: tamaño de salida\n","   * <tt>layers:  </tt>list of ints: tamaño de las capas intermedias que deseemos poner\n","   * <tt>p:       </tt>float: factor de dropout para cada capa (por simplicidad usaremos el mismo en todas las capas)\n","\n","<tt><font color=black>class TabularModel(nn.Module):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self, emb_szs, n_cont, out_sz, layers, p=0.5):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n","\n","\n","2. Generamos las capas embedded con  <a href='https://pytorch.org/docs/stable/nn.html#modulelist'><tt><strong>torch.nn.ModuleList()</strong></tt></a> y con  <a href='https://pytorch.org/docs/stable/nn.html#embedding'><tt><strong>torch.nn.Embedding()</strong></tt></a>\n","Los datos categóricos serán filtrados a través del Embeddings en la sección forward de la clase con el siguiente código:<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])</font></tt><br><br>\n","3. Incluidmos un factor dropout `p` en el embeddings con <a href='https://pytorch.org/docs/stable/nn.html#dropout'><tt><strong>torch.nn.Dropout()</strong></tt></a> Por defecto pondremos `p=0.5`<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.emb_drop = nn.Dropout(emb_drop)</font></tt><br><br>\n","4. Realizaremos una normalización sobre las variables continuas con <a href='https://pytorch.org/docs/stable/nn.html#batchnorm1d'><tt><strong>torch.nn.BatchNorm1d()</strong></tt></a><br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)</font></tt><br><br>\n","5. Definimos una secuencia de capas de red neuronal donde cada nivel incluirá una función lineal, una función de activación (en nuestro caso <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong>ReLU</strong></a>),\n","un paso de normalización y un factor de dropout. Para combinar la secuencia de capas usaremos <a href='https://pytorch.org/docs/stable/nn.html#sequential'><tt><strong>torch.nn.Sequential()</strong></tt></a>. Obsérvese que este código permite especificar **tantas capas ocultas** como especifiquemos en el argumento `layers`<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;layerlist = []<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;n_emb = sum((nf for ni,nf in emb_szs))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;n_in = n_emb + n_cont<br>\n","<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;for i in layers:<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(n_in,i)) <br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.ReLU(inplace=True))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.BatchNorm1d(i))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Dropout(p))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_in = i<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(layers[-1],out_sz))<br>\n","<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;self.layers = nn.Sequential(*layerlist)</font></tt><br><br>\n","6. Definimos el método `forward`. En este método se realiza el preprocesado de  embeddings sobre las categóricas y la normalización sobre las continuas antes de unirlas todas y pasarlas a través de las capas. <br>Usaremos <a href='https://pytorch.org/docs/stable/torch.html#torch.cat'><tt><strong>torch.cat()</strong></tt></a> para combinar los tensores en uno.<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;def forward(self, x_cat, x_cont):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;embeddings = []<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;for i,e in enumerate(self.embeds):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;embeddings.append(e(x_cat[:,i]))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat(embeddings, 1)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = self.emb_drop(x)<br>\n","<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x_cont = self.bn_cont(x_cont)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat([x, x_cont], 1)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = self.layers(x)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;return x</font></tt>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"xiIRjISWGByL"},"source":["### **Desglosando los pasos del Embedding** \n","Las siguientes celdas de código están unicamente con fines explicativos sobre los detalles del embedding"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1673696173411,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"rt9KEGpzGByL","outputId":"8429ee07-e19a-453a-c602-9fcca3d62b83"},"outputs":[{"data":{"text/plain":["tensor([[ 2,  0,  1],\n","        [ 9,  0,  2],\n","        [ 5,  0,  2],\n","        [15,  1,  3]])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Estos son nuestros datos origen, \n","catz = cats[:4]\n","catz"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1673696179247,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"isafo0iXGByL","outputId":"97a20af8-ccb7-4273-e2c3-140659997ce7"},"outputs":[{"data":{"text/plain":["[(24, 12), (2, 1), (7, 4)]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Esto es lo que pasamos cuando el instanciamos el modelo\n","emb_szs"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1673696185873,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"yerBPyszGByM","outputId":"1ab60e4b-91ae-4924-f047-8472eff5dd10"},"outputs":[{"data":{"text/plain":["ModuleList(\n","  (0): Embedding(24, 12)\n","  (1): Embedding(2, 1)\n","  (2): Embedding(7, 4)\n",")"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Esto se realiza en el metodo __init__\n","selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n","selfembeds"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1673696202289,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"UyvGJX2SGByM","outputId":"acb18fa0-a572-4507-c77a-4126bc1ddba1"},"outputs":[{"data":{"text/plain":["[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["list(enumerate(selfembeds))"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1673696210215,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"WCA1BQPXGByM","outputId":"51262c67-c01c-4bfc-8b38-6bb794eb6570"},"outputs":[{"data":{"text/plain":["[tensor([[-0.6127,  0.4208, -0.3203, -0.3310,  0.4134, -0.3144,  0.0377, -0.4242,\n","          -0.7633, -0.1815,  0.2110, -0.9944],\n","         [ 0.0539, -0.4279, -1.3367, -0.4229, -0.4742, -0.5943,  2.3040,  0.2095,\n","          -0.1058,  0.3270,  0.0887, -0.9326],\n","         [ 0.6614, -0.3628,  0.8361,  1.9471,  1.6211, -1.3923,  0.4575,  0.3620,\n","           0.6177, -0.9323, -0.5753, -1.0477],\n","         [-1.0242,  0.4803,  0.9331,  0.4421, -0.3151, -0.7337, -1.4280,  0.8523,\n","          -0.1702,  0.0184,  1.6837, -0.2467]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[-0.7893],\n","         [-0.7893],\n","         [-0.7893],\n","         [ 0.8837]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[ 1.0864,  0.2278, -0.9758,  0.9228],\n","         [ 0.3378, -0.5652, -1.0022, -0.4116],\n","         [ 0.3378, -0.5652, -1.0022, -0.4116],\n","         [ 0.7651, -0.4879, -0.4540, -0.3366]], grad_fn=<EmbeddingBackward0>)]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# Esto es lo que ocurre en el metodo forward()\n","embeddingz = []\n","for i,e in enumerate(selfembeds):\n","    #print(i,e)\n","    embeddingz.append(e(catz[:,i]))\n","embeddingz"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1673696354830,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"LyQ2VHilIrEP","outputId":"5e03f254-8091-4212-f02b-b62998cc10e3"},"outputs":[{"data":{"text/plain":["tensor([[-0.6341, -0.9960, -0.3154, -0.5080],\n","        [-0.3316,  0.0956, -0.6156, -1.8510],\n","        [-0.3316,  0.0956, -0.6156, -1.8510],\n","        [ 0.2076,  0.0775,  2.6578,  1.1731]], grad_fn=<EmbeddingBackward0>)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Lo anterior equivale a realizar esto: \n","nn.Embedding(24,12)(catz[:,0])\n","nn.Embedding(2,1)(catz[:,1])\n","nn.Embedding(7,4)(catz[:,2])\n","# e ir metiendo los resultados en una lista\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1673696380107,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"P5SLtMsjE9jR","outputId":"92f38c58-5772-4a90-a266-4be7f6044921"},"outputs":[{"data":{"text/plain":["tensor([[-0.7117, -1.0461,  0.4157, -0.7624,  1.2798, -1.1532],\n","        [-1.2391,  1.6432, -0.2995, -0.9944, -0.6964,  0.8896],\n","        [-0.3922, -0.7422, -0.3195, -0.4327,  2.6822, -1.7150],\n","        [ 0.1588, -1.3784, -1.0463, -0.7028,  0.3723,  0.3773]],\n","       grad_fn=<EmbeddingBackward0>)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["nn.Embedding(24,6)(catz[:,0])"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1673696388987,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"84uZTehDGByN","outputId":"abfc02ac-e017-4645-afce-56bece63cbd9"},"outputs":[{"data":{"text/plain":["tensor([[-0.6127,  0.4208, -0.3203, -0.3310,  0.4134, -0.3144,  0.0377, -0.4242,\n","         -0.7633, -0.1815,  0.2110, -0.9944, -0.7893,  1.0864,  0.2278, -0.9758,\n","          0.9228],\n","        [ 0.0539, -0.4279, -1.3367, -0.4229, -0.4742, -0.5943,  2.3040,  0.2095,\n","         -0.1058,  0.3270,  0.0887, -0.9326, -0.7893,  0.3378, -0.5652, -1.0022,\n","         -0.4116],\n","        [ 0.6614, -0.3628,  0.8361,  1.9471,  1.6211, -1.3923,  0.4575,  0.3620,\n","          0.6177, -0.9323, -0.5753, -1.0477, -0.7893,  0.3378, -0.5652, -1.0022,\n","         -0.4116],\n","        [-1.0242,  0.4803,  0.9331,  0.4421, -0.3151, -0.7337, -1.4280,  0.8523,\n","         -0.1702,  0.0184,  1.6837, -0.2467,  0.8837,  0.7651, -0.4879, -0.4540,\n","         -0.3366]], grad_fn=<CatBackward0>)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# Concatenamos los tensores resultantes de cada variable, con dimensiones (12,1,4) en uno (17)\n","z = torch.cat(embeddingz, 1)\n","z"]},{"cell_type":"code","execution_count":41,"metadata":{"collapsed":true,"executionInfo":{"elapsed":206,"status":"ok","timestamp":1673696430578,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"AlIGAgrOGByN"},"outputs":[],"source":["# Esto se ha definido en el metodo __init__()\n","selfembdrop = nn.Dropout(.4)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1673696435558,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"JwawJWpkGByN","outputId":"4a86e7da-7cce-4267-8c03-61257ddf0f63"},"outputs":[{"data":{"text/plain":["tensor([[-1.0211,  0.0000, -0.5339, -0.5516,  0.0000, -0.0000,  0.0628, -0.0000,\n","         -1.2722, -0.3024,  0.0000, -1.6573, -0.0000,  0.0000,  0.0000, -0.0000,\n","          1.5379],\n","        [ 0.0898, -0.7132, -0.0000, -0.0000, -0.7903, -0.0000,  3.8400,  0.3492,\n","         -0.0000,  0.5450,  0.0000, -1.5543, -0.0000,  0.0000, -0.0000, -1.6704,\n","         -0.0000],\n","        [ 1.1023, -0.0000,  1.3935,  0.0000,  0.0000, -2.3205,  0.7625,  0.0000,\n","          1.0295, -0.0000, -0.9588, -1.7462, -1.3155,  0.0000, -0.9420, -0.0000,\n","         -0.0000],\n","        [-1.7070,  0.0000,  1.5551,  0.7369, -0.0000, -1.2228, -2.3801,  1.4205,\n","         -0.2836,  0.0307,  0.0000, -0.0000,  1.4728,  1.2752, -0.8132, -0.7567,\n","         -0.5611]], grad_fn=<MulBackward0>)"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["z = selfembdrop(z)\n","z"]},{"cell_type":"markdown","metadata":{"id":"qZvpP7O5GByO"},"source":["**Así es como proporcionamos las variables categóricas a las capas**, concatenandolas previamente con las continuas. \n","\n","Teniendo en cuenta todo esto, esta es la definición de la clase: "]},{"cell_type":"code","execution_count":43,"metadata":{"collapsed":true,"executionInfo":{"elapsed":234,"status":"ok","timestamp":1673696487854,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"NjftU1GIGByQ"},"outputs":[],"source":["class TabularModel(nn.Module):\n","\n","    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n","        super().__init__()\n","        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n","        self.emb_drop = nn.Dropout(p)\n","        self.bn_cont = nn.BatchNorm1d(n_cont)\n","        \n","        layerlist = []\n","        \n","        n_emb = sum((nf for ni,nf in emb_szs))\n","        n_in = n_emb + n_cont\n","        \n","        # layers=[ 21 -> 100 -> 50 -> 32 -> 1]\n","        \n","        for i in layers:\n","            layerlist.append(nn.Linear(n_in,i)) \n","            layerlist.append(nn.ReLU(inplace=True))\n","            layerlist.append(nn.BatchNorm1d(i))\n","            layerlist.append(nn.Dropout(p))\n","            n_in = i\n","\n","        layerlist.append(nn.Linear(layers[-1],out_sz))\n","            \n","        self.layers = nn.Sequential(*layerlist)\n","    \n","    def forward(self, x_cat, x_cont):\n","        embeddings = []\n","        for i,e in enumerate(self.embeds):\n","            embeddings.append(e(x_cat[:,i]))\n","        x = torch.cat(embeddings, 1)\n","        x = self.emb_drop(x)\n","        \n","        x_cont = self.bn_cont(x_cont)\n","        x = torch.cat([x, x_cont], 1)\n","        \n","        x = self.layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"XLSiYv-KYtUe"},"source":["## Instanciamos el modelo y capas"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1673696573880,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"Ji1eKeAkY2BO"},"outputs":[],"source":["# Inicialmente configuramos dos capas ocultas de 10 y 100 neuronas respectivamente\n","capas = [20, 50, 100]"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1673696595481,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"7-IwmuPjiEHV","outputId":"f34ad8a2-fa62-4d12-e9e7-cac8cf285f34"},"outputs":[{"data":{"text/plain":["6"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["conts.shape[1]"]},{"cell_type":"code","execution_count":46,"metadata":{"collapsed":true,"executionInfo":{"elapsed":289,"status":"ok","timestamp":1673696601480,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"LmVK4ChNGByQ"},"outputs":[],"source":["torch.manual_seed(33)\n","model = TabularModel(emb_szs, conts.shape[1], 1, capas, p=0.4)"]},{"cell_type":"markdown","metadata":{"id":"8ivCSRU76bYg"},"source":["Comprobemos que la arquitectura es la correcta: "]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219,"status":"ok","timestamp":1673696611265,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"y_kjWxznGByR","outputId":"41493f1c-0db1-4cd7-bcdd-8760c32bedab"},"outputs":[{"data":{"text/plain":["TabularModel(\n","  (embeds): ModuleList(\n","    (0): Embedding(24, 12)\n","    (1): Embedding(2, 1)\n","    (2): Embedding(7, 4)\n","  )\n","  (emb_drop): Dropout(p=0.4, inplace=False)\n","  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layers): Sequential(\n","    (0): Linear(in_features=23, out_features=20, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Linear(in_features=20, out_features=50, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): Dropout(p=0.4, inplace=False)\n","    (8): Linear(in_features=50, out_features=100, bias=True)\n","    (9): ReLU(inplace=True)\n","    (10): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): Dropout(p=0.4, inplace=False)\n","    (12): Linear(in_features=100, out_features=1, bias=True)\n","  )\n",")"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"Z6RuEF59GByR"},"source":["## Definimos función de coste y optimizador\n","En ejercicios anteriores hemos usado la función de coste MSE. Sin embargo, resulta más interpretable (por estar en las mismas unidades que el target) emplear el RMSE. Dado que Pytorch no incorpora integrado la función <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE Loss</a> podemos calcularla simplemente aplicado la raiz cuadrada con <tt>torch.sqrt()</tt> al resultado de la función MSE durante el entrenamiento. \n","\n","Así pues definimos: "]},{"cell_type":"code","execution_count":48,"metadata":{"collapsed":true,"executionInfo":{"elapsed":229,"status":"ok","timestamp":1673696706136,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"2_QL4CF0GByR"},"outputs":[],"source":["criterion = nn.MSELoss()  # lo convertiremos a RMSE después\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"SN81m27pGByS"},"source":["## Preparamos conjuntos de train/test\n","En este punto, nuestro conjunt es un único lote de 120000 registros.  Esto llevará un tiempo de entrenamiento, por lo que podemos plantearnos reducirlo. Vamos a emplear 60000. Recordemos que los tensores ya estaban ordenados aleatoriamente."]},{"cell_type":"code","execution_count":49,"metadata":{"collapsed":true,"executionInfo":{"elapsed":205,"status":"ok","timestamp":1673696713530,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"ORraM46BGByS"},"outputs":[],"source":["batch_size = 60000\n","test_size = int(batch_size * .2)\n","\n","cat_train = cats[:batch_size-test_size]\n","cat_test = cats[batch_size-test_size:batch_size]\n","con_train = conts[:batch_size-test_size]\n","con_test = conts[batch_size-test_size:batch_size]\n","y_train = y[:batch_size-test_size]\n","y_test = y[batch_size-test_size:batch_size]"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1673696718151,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"-f0hIUHpGByS","outputId":"11c37a72-61f0-4ba0-925c-fdc58ffc790d"},"outputs":[{"data":{"text/plain":["48000"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["len(cat_train)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1673696719746,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"FKY3pW2zGByT","outputId":"0c65af3d-3b7a-4bea-d729-ee2a342dac95"},"outputs":[{"data":{"text/plain":["12000"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["len(cat_test)"]},{"cell_type":"markdown","metadata":{"id":"YDbGD4JOGByT"},"source":["## Entrenando el modelo \n","\n","En ejercicios anteriores, el proceso de entrenamiento lo hemos definido en una función `fit` donde integramos el entrenamiento y la validación. Esto no es necesario realizarlo así siempre. Podemos simplemente realizar el bucle de entrenamiento para los epochs que queramos y después aplicar el modelo en el conjunto de test. Esta separación puede ser ineresante (o necesaria) cuando el modelo tarda mucho en la fase de entrenamiento. \n","\n","Es posible que nuestro modelo  tarde 30 min o más. Añadimos algunas líneas de código para observar al final la duración.\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52385,"status":"ok","timestamp":1673696946294,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"XHuDDrRxGByT","outputId":"d0639cd3-f552-4c44-8941-3a01a3be906a"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch:   1  loss: 12.44403553\n"]},{"name":"stdout","output_type":"stream","text":["epoch:  26  loss: 11.41765881\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import time\n","start_time = time.time()\n","\n","epochs = 300\n","losses = []\n","\n","for i in range(epochs):\n","    i+=1\n","\n","    y_pred = model(cat_train, con_train)\n","    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n","    losses.append(loss)\n","    \n","    # Mostramos en pantalla cada 25 epochs:\n","    if i%25 == 1:\n","        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n","print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"]},{"cell_type":"markdown","metadata":{"id":"PW6mAuK1GByU"},"source":["## Visualizamos la función de error "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYID4JaCfyCq"},"outputs":[],"source":["losses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":677,"status":"ok","timestamp":1673696868821,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"1dAZvynkGByU","outputId":"3fcdd4d7-8467-4887-c541-9994aea6be5f"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8dcne0AChBBG2DJkCwEBEXDgqoiCgANBHGitdVWt/WlbWzu0VVsHikoVXIh1a62iCCiCQJgiGyEMgQCBBAiEjO/vj3u1EUkII/fc8X4+HveRe09uct6HA2/O/d5zv8ecc4iISOSI8jqAiIgElopfRCTCqPhFRCKMil9EJMKo+EVEIkyM1wGqom7duq5Zs2ZexxARCSnz58/f4ZxLP3R5SBR/s2bNyM7O9jqGiEhIMbOcwy3XUI+ISIRR8YuIRBgVv4hIhFHxi4hEGBW/iEiEUfGLiEQYFb+ISIQJ6+KfvjKXf81cR96+g15HEREJGiHxAa5j9dmKXF6cncND/13BgHYZDO7aiL6t04mNDuv/70REKmWhcCGWrKwsd6yf3F2xtYDJ8zbyzsLN7Cospm6NOAZ2bsiQrpm0b5iCmZ3gtCIiwcHM5jvnsn6yPNyL/3sHS8qYsWo7by3YxNTluRwsLaN1Rg0Gd83kos4NaVgr8QSlFREJDhFf/OXtLjzIB0u28PbCzczP2QVA4zqJDD4lk2HdG9NI/wmISBhQ8Vdg3Y59TF2+jRmrtjNzzQ4ATm+VzoCT69GvdT2apCVVy3pFRKqbir8KNuYV8nr2Rt5ZtJmNefsBaJGezFU9mzK8e2OS4sL6vXARCTMq/qPgnGP9zkJmrMzlgyVbyM7ZRWpiLBd1bsiYvi1oXEevAkQk+Kn4j8P8nDwmzMphyjdbKXOO8zs0YETPpnRvVltnBYlI0Kqo+DV2UQXdmtahW9M6bM0/wLgZa3lzwSbeW/wdrTNqcOWpTRmW1ZjEuGivY4qIVEm1HfGb2fPAhUCuc66Df9nfgYHAQWAtMNo5t/tIv8vrI/5DFR4s4YPFW3h5Tg5LNuWTkRLPrwa0YUi3TKKj9ApARIJDRUf81fkR1gnAeYcs+wTo4JzrBKwCflON6682SXExDOvemPdu7sPkMT1pkJrI3W8u4YLHvmDaylxCYfhMRCJXtRW/c+5zIO+QZVOccyX+h18BmdW1/kA5tUUab9/Um7FXdOVASSmjX5jHlePnsHRzvtfRREQOy8tJa64B/uvh+k8YM+NnnRrwye39+P3AdizfUsCFT8zkttcWsiV/v9fxRER+xJPiN7N7gRLglUqeM8bMss0se/v27YELdxziYqIYfVpzZtx9Bjf1b8l/l27lnEc/579fb/E6mojIDwJe/GZ2Nb43fa90lQyGO+eedc5lOeey0tPTA5bvREhJiOXu89oy5fa+nJRRg5+/soBbX1vImtw9XkcTEQls8ZvZecDdwEXOucJArtsLTdOSmXR9T0af1ozPVuRyydhZfOmfFkJExCvVVvxmNgmYDbQxs01mdi3wJFAT+MTMFpnZuOpaf7BIiI3m9wPb89FtfWlQK4FRz89l/BffUlJa5nU0EYlQ+uRuABUcKOb21xYxdUUu3ZvV5ukR3ahbI97rWCISprw4j18OkZIQy/hRWfxjeGeWbMpn0JNfsuy7Aq9jiUiEUfEHmJlxySmZ/PvGXpSWOS4dN4uPlm71OpaIRBAVv0c6ZdbivZtPo3VGTW58eT5jp63RJ35FJCBU/B6ql5LAa2N6cnGXhvz945X85cPlXkcSkQig2Tk9lhAbzT+GdyElMZbnvlhHraQ4buzXUpO9iUi1UfEHATPj9wPbs2NvEX//eCXZ6/N4dmQWsdF6QSYiJ56aJUhERxljr+jKHy5qz7SV27nxpfls31PkdSwRCUMq/iBiZozq3Yz7B7bji9U7GPjETFZu1TQPInJiqfiD0NWnNeftX/TG4Rj1/FzyC4u9jiQiYUTFH6TaN0zluZFZ7NhbxO2vL2L/wVKvI4lImFDxB7FOmbW4/6L2TFuZy7BnZrM1/4DXkUQkDKj4g9yInk0ZPzKLb7fvZcjTs9i8Wxd2EZHjo+IPAWednMHkG3pRcKCYEePn6GwfETkuKv4Q0aFRKi9c3Z2t+QcY9fxcjfmLyDFT8YeQrGZ1eOrKrizfWsBdbyzWnP4ickxU/CHmjLb1+PV5bflgyRZufnUhRSU68heRo6PiD0E39mvJ7y5sx0ffbOW6idkcKFb5i0jVqfhD1DV9mvO3Szvxxeod3PzqQoo17CMiVaTiD2HDshrzx0Ht+XT5Nu7892JKyzSfv4gcmWbnDHEjezVjb1EJf/toJUlxMfz54g5EaUpnEamEij8M3NT/JPYVlTB22lqiDB4YpPIXkYqp+MPEnee0oczB09PXUubQkb+IVEjFHybMjLvPbUOUwdhpa3HO8ZdLOqr8ReQnVPxhxMy485w2GMaT09bgHPx1sMpfRH5MxR9mzIxfndOaKIPHP1uDGTxwcQddxlFEfqDiD0Nmxu0DWlPm4Mlpa1ixdQ8TR/cgNSnW62giEgR0GBimzIw7z23Dk1ecwjff5XP9S9ma3kFEABV/2LuwU0MeHtqZuevyuGPyYg6W6BO+IpFOQz0RYFCXRuQWFPHnD5ezefd+xo/Kom6NeK9jiYhHdMQfIa7v24KnruzKiq0FDB03m4UbdnkdSUQ8ouKPIBd0bMDL155K4cESBj89i7HT1uCc5vcRiTQq/giT1awOU3/Vn4GdGvL3j1fy8JSVKn+RCKMx/ghUIz6Gxy7rQnJ8NGOnrWVt7j4euLgD6TU17i8SCXTEH6HMjD9d3JF7zm/LZytzOecfM1iyabfXsUQkAFT8ESw6yrixX0s+vKUPyfExjHp+Lqu37fE6lohUMxW/cFK9mrxy3anEREcx4l9zeD17oz7sJRLGVPwCQNO0ZF66tgfJ8THc/cYSzv3H5yzdnO91LBGpBtVW/Gb2vJnlmtnScsvqmNknZrba/7V2da1fjl7b+ilMvaMfE0Z352BJGZc9+xVfrtnhdSwROcGq84h/AnDeIcvuAaY651oBU/2PJYiYGf3b1OOtm06jUa1Ern5hLnf9ezEb8wq9jiYiJ0i1Fb9z7nMg75DFg4CJ/vsTgYura/1yfOqnJvD6Db0Y0jWT/3y9hQse/4L3F3/ndSwROQECPcaf4Zzb4r+/Fcio6IlmNsbMss0se/v27YFJJz+SmhTLg0M68dGtfTmpXg1+OWkh17+YzYadOvoXCWWevbnrfB8XrfAjo865Z51zWc65rPT09AAmk0M1SUvi9Rt6cfd5bfhyzQ7OfnQGf/toBfsP6swfkVAU6OLfZmYNAPxfcwO8fjlGsdFR3NT/JKbd2Z8LOzXgqelruX3yIk33IBKCAl387wGj/PdHAe8GeP1ynDJSEnh0eBfuveBkPvpmKz97fCYzV+vMH5FQUp2nc04CZgNtzGyTmV0LPAgMMLPVwNn+xxKCrju9Ob+7sB0Hiku5ZuI8Hpmyki35+72OJSJVYKHwUj0rK8tlZ2d7HUMOY9e+g9w8aQGz1+4krUY8P+/Xkgs7NaBeSoLX0UQinpnNd85lHbpcn9yV41I7OY5XruvJx7f1pWZCDH/8YBnnP/YFU5dv8zqaiFRAxS8nRKuMmky9ox8f39aXtBpxXDsxm9snL9KZPyJBSMUvJ4yZ0aZ+TT745encdnYr3lm0mcFPz2LW2h26yLtIEFHxywkXFxPFbWe35oWru/Pd7v1c8dwchj87m31FJV5HExFU/FKN+repx+d3ncFfB3dkyaZ8uvxxCr95awmlZcF/QoFIONOlF6VapSbFcnmPJjSvm8xbCzYxae5GSkodDw3pRFSUeR1PJCKp+CUgerZIo2eLNBqkJvLY1NV8sXoH/duk88DFHYiN1gtPkUBS8UtA3XZ2K+okx/HF6u28Nm8j63fu4/6L2tO2forX0UQihg61JKDMjFG9mzF+VHceGtKRFVv3MPipWUxboWmbRAJFxS+eGd69CVNu70vTtGRGT5jHnf9ezK59B72OJRL2jlj8ZtbSzOL99/ub2S1mVqv6o0kkqFczgbd+3puf92/JOws3c9ajM/hgiS74IlKdqnLE/yZQamYnAc8CjYFXqzWVRJTEuGh+fV5bPrilD03qJHHzqwt59vO1FJfqQ18i1aEqxV/mnCsBLgGecM7dBTSo3lgSidrWT2HyDT05++QM/vLhCgY8OkMXexepBlUp/mIzuxzf/Pkf+JfFVl8kiWTxMdE8N7Ib40dm4YArx8/h3re/pkwf+hI5YapyOudo4Ebgz865dWbWHHipemNJJDMzzm6XQZ9WdXn445WMn7mOvUUl3NC3Je0a6rRPkeN1xOJ3zi0DbgEws9pATefcQ9UdTCQhNpr7LmxHfGwUT09fy4dfb2HyDb3o2qS219FEQlpVzuqZbmYpZlYHWAA8Z2aPVn80EZ+7zm3LnP87m/qpCVw3MZt3F232OpJISKvKGH+qc64AGAy86Jw7Fd9lE0UCJr1mPBNG96BJnSRufW0RD/53BSU660fkmFSl+GPMrAEwjP+9uSsScC3Ta/DGjb244tQmjJuxlkuemsXyLQVexxIJOVUp/j8CHwNrnXPzzKwFsLp6Y4kcXkx0FH+5pCNPXdmVLfn7GfjETB77dDWhcO1okWChi61LyMrbd5D73/uG9xZ/x6heTfndwPZEa6pnkR8c88XWzSzTzN42s1z/7U0zy6yemCJVVyc5jscu68J1fZozcXYOI8bPYX5OntexRIJeVYZ6XgDeAxr6b+/7l4l4zsy492cn87chnVi+tYAhT8/m/cWa60ekMlUp/nTn3AvOuRL/bQKQXs25RKrMzBjWvTGz7jmT7s1q86vXFzPhy3Ua9xepQFWKf6eZjTCzaP9tBLCzuoOJHK2kuBieG5lFn1Z1uf/9Zfzjk1Uqf5HDqErxX4PvVM6twBbgUuDqaswkcsxqJcUxfmQWQ7tl8vhnaxg6bjbz1mvcX6S8Ixa/cy7HOXeRcy7dOVfPOXcxcGsAsokck6go48EhnfjLJR3ZkFfI0HGzeXP+Jq9jiQSNY70C17ATmkLkBIuOMq44tQkz7jqD3i3T+PWbS3hp9noN/Yhw7MWvk6UlJCTGRTPuqm70aVWX3777DU9+tsbrSCKeq7D4zaxOBbc0VPwSQlISYnl+VHcGd23EI5+s4tU5G7yOJOKpyqZlng84Dl/yuiK2hJSoKOOhIZ3YXVjMve98TUy0MSyrsdexRDxR4RG/c665c66F/+uhtxaBDClyIsRGRzH2iq70Oakud7+xhGsmzGPn3iKvY4kE3LGO8YuEpMS4aP41qjt3ntOamat38Of/LPc6kkjAVeXSiyJhJS4mipvPbMX+4lLGTlvLoo27+cvgjvRskeZ1NJGA0BG/RKybz2jFL85oycHSMm59bSHf7d7vdSSRgKjsrJ4zy91vfsj3BldnKJFASIyL5q5z2zJuRDfy9xcz4NEZfLlmh9exRKpdZUf8D5e7/+Yh37uvGrKIeKJDo1Sm3NaPRrUTufnVBazfsc/rSCLVqrLitwruH+7xUTGz283sGzNbamaTzCzheH6fyPFqkpbE0yO6UVrmGPjkTOZ8q3kIJXxVVvyugvuHe1xlZtYIuAXIcs51AKKBy47194mcKC3Ta/DBL0+nXs14rn8xmzW5e7yOJFItKiv+Fmb2npm9X+7+94+bV/JzVREDJJpZDJAE6MoZEhSapCUxYXQPYqOjuOmVBew/WOp1JJETrsJr7ppZv8p+0Dk345hXanYr8GdgPzDFOXflYZ4zBhgD0KRJk245OTnHujqRo/b5qu2MfH4urTNqMPaKrrTKqOl1JJGjdtTX3HXOzSh/A2YBBcDy4yz92sAgfK8aGgLJ/ou7HLr+Z51zWc65rPR0XfBLAqtv63SevzqLvH3FjNYnfCXMVHY65zgza++/nwosBl4EFprZ5cexzrOBdc657c65YuAtoPdx/D6RanFm2wzGj8oid08RP3t8Jos37vY6ksgJUdkY/+nOuW/890cDq5xzHYFuwN3Hsc4NQE8zSzIzA84C9Ll5CUpdGtfijRt7ER1ljHkpW6d6SliorPjLz8A5AHgHwDm39XhW6JybA7wBLAC+9md49nh+p0h16pRZi+dGZpG/v5j+D09n/Bffeh1J5LhUVvy7zexCMzsFOA34CMB/Jk7i8azUOfd751xb51wH59xVzjkNoEpQa9cwhU9u70ff1uk8MmUVuQUHvI4kcswqK/4bgJuBF4Dbyh3pnwX8p7qDiQSbxnWSeGBQe0rKyhj6zGyydRF3CVGVndWzyjl3nnOui3NuQrnlHzvnfhWQdCJBpmlaMhNG98A5uO7FbDbmFXodSeSoVXYe/+OV/aBz7pZqSXQYWVlZLjs7O1CrEzminJ37GPjETBrVTuKtn/cmMS7a60giP3HU5/EDNwJ98H2qNhvfpRjL30QiVtO0ZB6//BRWbC3Qlbwk5FRW/A3wnW1zLnAVEAu865yb6JybGIhwIsGsf5t6PDK0Mws27OKyZ79i1z5dilpCQ2Vj/Dudc+Occ2fgO4+/FrDMzK4KWDqRIDe4ayYTRvcgJ6+QqyfMY29RideRRI7oiFfgMrOuwK3ACOC/aJhH5Ed6tUxj7BVdWbo5nzEvZnOgWBO7SXCrbMqGP5rZfOAOYAa+aZSvdc4tC1g6kRAxoF0Gf7+0E7PW7uSWSQspKS3zOpJIhSo74r8P3/BOZ+CvwAIzW2JmX5vZkoCkEwkhg7tm8rsL2zFl2Tb+9B/NQiLBK6aS7x3vnPsiEeeaPs3ZkFfIxNnrGdSlIac0qe11JJGfqOzN3ZzD3YCN+E7zFJHDuPPcNmTUTOCXkxbqA14SlCob408xs9+Y2ZNmdo75/BL4FhgWuIgioaVGfAzPjcxiz4EShj8zWzN6StCpbIz/JaANvhk0rwOmAZcCFzvnBgUgm0jI6piZyqTre3KgpIwrnvuKbZrUTYJIpdfcdc5d7Zx7BrgcaAec65xbFJhoIqGtXcMUXrymB/n7ixn4xEzeXbTZ60giQOXFX/z9HedcKbDJOafDFpGj0KFRKq9e35MGtRK54/XFzPl2p9eRRCot/s5mVuC/7QE6fX/fzAoCFVAk1HVuXIuXr+1BkzpJ/HLSQrbv0bw+4q3KzuqJds6l+G81nXMx5e6nBDKkSKirmRDLU1d2JX9/Mbe+tpDSssPPiisSCEecskFEToyTG6TwwKAOzFq7k8c+XeV1HIlgKn6RABrWvTGXdsvkiWlrmL4y1+s4EqFU/CIB9sCgDrTJqMltkxexefd+r+NIBFLxiwRYYlw0T4/oRkmp46ZXFlBUotk8JbBU/CIeaF43mYeHdmLxxt088MEyKroEqkh1UPGLeOS8Dg0Y07cFL3+1gbHT1qj8JWAqm51TRKrZPee1ZWv+AR6esopvd+zj4Us7ExVlXseSMKfiF/FQVJTxz+FdaJqWxBOfraFNRk1u6NfS61gS5lT8Ih6LijLuGNCaNbl7efCjFaQmxnJZjyZex5IwpjF+kSBgZjw6rAt9W6Vzz1tf86+Z67yOJGFMxS8SJBLjonl2ZDfO71CfBz5YxpOfrfY6koQpFb9IEImPieaJy0/hklMa8fCUVcxau8PrSBKGVPwiQSYmOoq/Du5IkzpJ3Pf2UvILi4/8QyJHQcUvEoQSYqN5aEgnNu3az8jn51BwQOUvJ46KXyRI9WqZxtgru/LNdwWMfmEee4tKvI4kYULFLxLEBrTL4InLT2HRxt1cO2EeJaVlXkeSMKDiFwly53dswENDOjFnXR6vzNngdRwJAyp+kRAwpGsj+pxUl0c/WUVugS59LcdHxS8SAsyMPwxqT1FJKbe+pnn85fio+EVCRMv0GjwwqANfrdtJ/79P44Ml33kdSUKUJ8VvZrXM7A0zW2Fmy82slxc5RELN0KzGfH7XGZzSuDa3TFrI3HV5XkeSEOTVEf9jwEfOubZAZ2C5RzlEQk7jOkm8MLo7mbWTuPPfi9m5t8jrSBJiAl78ZpYK9AX+BeCcO+ic2x3oHCKhLDk+hkeHdWZbwQGGPD2LaSt04XapOi+O+JsD24EXzGyhmY03s+RDn2RmY8ws28yyt2/fHviUIkEuq1kdXr3+VEqdY/SEeby/WGP+UjVeFH8M0BV42jl3CrAPuOfQJznnnnXOZTnnstLT0wOdUSQkdGtah6l39Kdz41r87t2lbN+jYR85Mi+KfxOwyTk3x//4DXz/EYjIMYiLieKRoZ3Yd7CU+975WtfulSMKePE757YCG82sjX/RWcCyQOcQCScn1avJnee05uNvtvHbd5dqageplFeXXvwl8IqZxQHfAqM9yiESNq7r04Kdew/yzOffUj8lgZvPbOV1JAlSnhS/c24RkOXFukXCVVSU8ZsLTmbT7v3889PVzFu/iwcGdaBJWpLX0STI6JO7ImHmT4M6MLhrI+bn7OLONxZTVqYxf/kxFb9ImKmdHMffLu3Mby88mbnr8nhlrmb0lB9T8YuEqWFZjelzUl0e/HA563bs8zqOBBEVv0iYMjP+OrgjcTFRDH9mtspffqDiFwljjeskMfmGXpSUOa5/MZs9unavoOIXCXutM2ry5BWnsG7HPkaMn8PuwoNeRxKPqfhFIkDvlnUZN6Iby7fs4eZXF+oDXhFOxS8SIQa0y+BPl3Rg5pod3PraIg4Ul3odSTzi1Sd3RcQDw7Iak19YzJ8/XM72vUU8d1UWqUmxXseSANMRv0iEub5vCx67rAsLN+xi6DOz+E7X7404Kn6RCDSoSyMmju7Blt0HGPzULFZu3eN1JAkgFb9IhOp9Ul0m39CLMucYOm4WX2/K9zqSBIiKXySCtWuYwls39SYuJpq/fbzC6zgSICp+kQiXWTuJ0ac144vVO/jV64uZtz7P60hSzVT8IsLlPZpQIz6GNxds4o7XdapnuFPxiwh1kuOYfld/Xri6Oxvz9nP75EX6hG8YU/GLCAB1a8RzRtt63HVuGz5Zto2h42Yze+1Oikp09B9uVPwi8iO/OOMkXrr2VDbv3s/lz33F5c9+xf6DKv9wouIXkZ/o1TKN6Xf2508Xd2Dhxt3c/OoCze8TRlT8InJY9VISGNGzKX8c1IGpK3K59+2lOKfLOIYDzdUjIpW6qmdTthcc4PHP1jBl2VZaZdTkvp+dTKfMWl5Hk2OkI34ROaLbB7Tm/y5oy5ltM1i/Yx83vDRf4/4hTMUvIkdkZozp25JHhnXmictPYUv+Af45dZWGfkKUil9EjsqpLdIYlpXJMzO+ZfgzX/He4u+8jiRHSWP8InLUHhzciRbpNXg9eyO3TFpI3t4irurVjOgo8zqaVIGO+EXkqEVFGTf2a8mHt5xOv9bp3P/+MoY/M5v8Ql3MPRSo+EXkmCXERvPC1d15eGhnFm/azYB/zGDCl+u8jiVHoKEeETkuUVHGpd0yaZaWxCNTVnH/+8v4cOlW6qck8M/hXYjS8E/QUfGLyAmR1awOL17bg2smzGNBzi7mrssjMTaa9o1SOLd9fTJSEryOKH4WCqdjZWVluezsbK9jiEgVlJU5ypzjhpfmM3VFLgDJcdE8Mqwz57avj5leAQSKmc13zmUdulxH/CJyQkVFGVEY467qxp4DJeTtK+K2yYu48eUFpCbGkpIYQ5fGtamfEs//XXCy/iPwgIpfRKpFbHQUdZLjqJMcx5s/7807CzezeFM+2/IPMHfdTrYVFNG1SW3O79jA66gRR0M9IhJwJaVlnPfYFxQWldCvTTob8goZltWYn3VsQEy0TjY8USoa6tGfsIgEXEx0FA8O7khCbDRvLtjMhrxCbn1tEWc8Mp3X5m5g+spcduwtYmNeoddRw5KO+EXEM845SsscUWZ8unwbj36yihVb9/zoOWe1rUfTtGRuPasVqUmxHiUNTXpzV0SCjpkRE+17c/ec9vU5s209Vm3by859RSzdXED+/mLemL+R6au2s2DDLgA2797P7We3ZtOuQk5ukMIFHRtoqoijpCN+EQl6L3+Vw33vLKVTZipFxWWs3Pa/VwUjezXlzLb1aNcwhXo1E9i5t4hpK7cTFxNFg9QEOmfWIi4mMke1Kzri96z4zSwayAY2O+curOy5Kn4Ryd9fTGpiLLv2HeSFWeu5tGsmz3+5jgmz1gNgBq3r1WTN9r2Ulv2v15rXTebX57UhLiaKouIyTm+dTo34GMrKHI9+sooujWtxdrsMj7aqegVj8d8BZAEpKn4RORYlpWW8v+Q76taIZ+GG3Xz17U46Zdbiwk4NiI+JYsXWPfzz01Ws3b7vh5/p0CiFlIRYCg4Us3RzAXHRUfzqnNas31lIcWkZ2woO0DQtiQs6NiDKjOS4GJrVTaJmwk/fX1i0cTc5O/cxsFPDoJyaIqiK38wygYnAn4E7VPwiUl2KS8uY8s02aifHkltQxB2vL6JOchxgnNM+g0UbdrNsSwE14mNIjIsmJSGG9TsLf/SqoUZ8DJm1E6mZEENacjxz1/umo9i+p4iDpWXUSY4js3Yio3o1IyevkPiYKHq3TGN+zi7a1k+hY2YqqYmxP1y45mBpGfEx0UfM/v2rnGMVbMX/BvBXoCZw5+GK38zGAGMAmjRp0i0nJyewIUUkLK3YWkCDlMQfzhByzrF9TxEpibEkxPrKOGfnPjbv2g9AwYESPlq6hbzCYnJ27mPvgRLOOrkeO/YeJDEumt4t01i4YTczV+9ga8EBogzKDqnVuJgo2jdMYenmfGomxFKwv5jzOtSnb+t0EmOjaV43mdezN3JR54Zk5+zi3UXfMbBzA56evpaxV3Slb+v0Y9rWoCl+M7sQuMA5d5OZ9aeC4i9PR/wiEiycc4edZmJvUQnrd+yjZXoN5q7PY966PIZ3b0zOzkLeXriZxZt2c1rLNAoPlpIQG817i78jf//hr1+QmhhL/v5i2tavySvXnUpajfhjyhpMxf9X4CqgBEgAUoC3nHMjKvoZFb+IhJuS0jJy8grZmFfIp8u3cUWPpizdnE/HzFQapCYwae5Ghndv7B+WOjZBU/w/WrmO+EVEqo2mbBAREcDjT+4656YD073MICISaXTELyGxboUAAAZASURBVCISYVT8IiIRRsUvIhJhVPwiIhFGxS8iEmFU/CIiESYk5uM3s+3AsU7WUxfYcQLjeEnbEpy0LcFJ2wJNnXM/megnJIr/eJhZ9uE+uRaKtC3BSdsSnLQtFdNQj4hIhFHxi4hEmEgo/me9DnACaVuCk7YlOGlbKhD2Y/wiIvJjkXDELyIi5aj4RUQiTFgXv5mdZ2YrzWyNmd3jdZ6jZWbrzexrM1tkZtn+ZXXM7BMzW+3/WtvrnIdjZs+bWa6ZLS237LDZzedx/35aYmZdvUv+YxVsx/1mttm/XxaZ2QXlvvcb/3asNLNzvUl9eGbW2MymmdkyM/vGzG71Lw/F/VLRtoTcvjGzBDOba2aL/dvyB//y5mY2x595spnF+ZfH+x+v8X+/2VGv1DkXljcgGlgLtADigMVAO69zHeU2rAfqHrLsb8A9/vv3AA95nbOC7H2BrsDSI2UHLgD+CxjQE5jjdf4jbMf9+K4cd+hz2/n/nsUDzf1//6K93oZy+RoAXf33awKr/JlDcb9UtC0ht2/8f741/PdjgTn+P+/Xgcv8y8cBP/ffvwkY579/GTD5aNcZzkf8PYA1zrlvnXMHgdeAQR5nOhEGARP99ycCF3uYpULOuc+BvEMWV5R9EPCi8/kKqGVmDQKTtHIVbEdFBgGvOeeKnHPrgDX4/h4GBefcFufcAv/9PcByoBGhuV8q2paKBO2+8f/57vU/jPXfHHAm8IZ/+aH75fv99QZwlh3u6u+VCOfibwRsLPd4E5X/xQhGDphiZvPNbIx/WYZzbov//lYgw5tox6Si7KG4r272D388X264LWS2wz88cAq+o8uQ3i+HbAuE4L4xs2gzWwTkAp/ge0Wy2zlX4n9K+bw/bIv/+/lA2tGsL5yLPxz0cc51Bc4HfmFmfct/0/le64Xk+bihnB14GmgJdAG2AI94G+fomFkN4E3gNudcQfnvhdp+Ocy2hOS+cc6VOue6AJn4Xom0rc71hXPxbwYal3uc6V8WMpxzm/1fc4G38f2F2Pb9y23/11zvEh61irKH1L5yzm3z/0MtA57jf0MGQb8dZhaLryhfcc695V8ckvvlcNsSyvsGwDm3G5gG9MI3tPb9ddHL5/1hW/zfTwV2Hs16wrn45wGt/O+Mx+F7E+Q9jzNVmZklm1nN7+8D5wBL8W3DKP/TRgHvepPwmFSU/T1gpP8skp5Afrmhh6BzyDj3Jfj2C/i24zL/WRfNgVbA3EDnq4h/HPhfwHLn3KPlvhVy+6WibQnFfWNm6WZWy38/ERiA7z2LacCl/qcdul++31+XAp/5X6lVndfvaFfnDd9ZCavwjZfd63Weo8zeAt9ZCIuBb77Pj28sbyqwGvgUqON11gryT8L3UrsY3/jktRVlx3dWw1j/fvoayPI6/xG24yV/ziX+f4QNyj3/Xv92rATO9zr/IdvSB98wzhJgkf92QYjul4q2JeT2DdAJWOjPvBT4nX95C3z/Oa0B/g3E+5cn+B+v8X+/xdGuU1M2iIhEmHAe6hERkcNQ8YuIRBgVv4hIhFHxi4hEGBW/iEiEUfGLVDMz629mH3idQ+R7Kn4RkQij4hfxM7MR/nnRF5nZM/6Js/aa2T/886RPNbN0/3O7mNlX/snA3i43h/1JZvapf271BWbW0v/ra5jZG2a2wsxeOdrZFEVOJBW/CGBmJwPDgdOcb7KsUuBKIBnIds61B2YAv/f/yIvAr51znfB9UvT75a8AY51znYHe+D71C77ZI2/DNy98C+C0at8okQrEHPkpIhHhLKAbMM9/MJ6Ib7KyMmCy/zkvA2+ZWSpQyzk3w798IvBv/9xKjZxzbwM45w4A+H/fXOfcJv/jRUAzYGb1b5bIT6n4RXwMmOic+82PFpr99pDnHescJ0Xl7peif3viIQ31iPhMBS41s3rww3Vom+L7N/L9DIlXADOdc/nALjM73b/8KmCG810JapOZXez/HfFmlhTQrRCpAh11iADOuWVmdh++K55F4ZuN8xfAPqCH/3u5+N4HAN+0uOP8xf4tMNq//CrgGTP7o/93DA3gZohUiWbnFKmEme11ztXwOofIiaShHhGRCKMjfhGRCKMjfhGRCKPiFxGJMCp+EZEIo+IXEYkwKn4RkQjz/xcNomMgSVLXAAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["losses= [ loss.detach().numpy() for loss in losses]\n","plt.plot(range(epochs), losses)\n","plt.ylabel('RMSE Loss')\n","plt.xlabel('epoch');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7f9CNQpqqUV"},"outputs":[],"source":["losses"]},{"cell_type":"markdown","metadata":{"id":"MgMLMPTPGByU"},"source":["## Validamos el modelo\n","Ahora vamos a lanzar el modelo con el conjunto de test y a comparar los resultados con las etiquetas conocidas. \n","\n","Dado que en este paso no es necesario actualizar pesos ni biases, no es necesario emplear la función autograd, por lo que ponemos <tt>torch.no_grad()</tt> y evitamos cálculos (y tiempo ) innecesario."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1673696963365,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"oiWCWvvkGByV","outputId":"2a052b74-42af-4930-e586-66b0527bb75a"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 3.46528745\n"]}],"source":["# (método validation_step en el ejemplo anterior)\n","with torch.no_grad():\n","    y_val = model(cat_test, con_test)\n","    loss = torch.sqrt(criterion(y_val, y_test))\n","print(f'RMSE: {loss:.8f}')"]},{"cell_type":"markdown","metadata":{"id":"Wa9wsFiZGByV"},"source":["Esto quiere decir que como promedio, los valores predichos por el modelo difieren &plusmn;$3.58 del valor real.\n","\n","Observemos los primeros 50 valores y sus diferencias:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1673696969026,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"F6swMpo0GByV","outputId":"eeacecef-d005-4770-f42c-df28cfbc4546"},"outputs":[{"name":"stdout","output_type":"stream","text":["   PREDICTED   ACTUAL     DIFF\n"," 1.   2.4351   2.9000   0.4649\n"," 2.  20.2133   5.7000  14.5133\n"," 3.   8.1666   7.7000   0.4666\n"," 4.  12.9146  12.5000   0.4146\n"," 5.   5.1450   4.1000   1.0450\n"," 6.   5.8217   5.3000   0.5217\n"," 7.   3.9162   3.7000   0.2162\n"," 8.  22.3013  14.5000   7.8013\n"," 9.   3.1544   5.7000   2.5456\n","10.  12.1350  10.1000   2.0350\n","11.   5.3903   4.5000   0.8903\n","12.   5.3870   6.1000   0.7130\n","13.   5.4671   6.9000   1.4329\n","14.  14.6846  14.1000   0.5846\n","15.   5.4076   4.5000   0.9076\n","16.  29.6067  34.1000   4.4933\n","17.   2.0120  12.5000  10.4880\n","18.   4.4119   4.1000   0.3119\n","19.  10.4935   8.5000   1.9935\n","20.   6.3184   5.3000   1.0184\n","21.  14.6587  11.3000   3.3587\n","22.  10.1374  10.5000   0.3626\n","23.  14.2242  15.3000   1.0758\n","24.  17.9781  14.9000   3.0781\n","25.  49.7462  49.5700   0.1762\n","26.   5.2821   5.3000   0.0179\n","27.   5.3855   3.7000   1.6855\n","28.   6.0564   6.5000   0.4436\n","29.  15.7561  14.1000   1.6561\n","30.   6.9709   4.9000   2.0709\n","31.   4.3806   3.7000   0.6806\n","32.  43.9786  38.6700   5.3086\n","33.  11.1748  12.5000   1.3252\n","34.  12.7647  16.5000   3.7353\n","35.   6.8854   5.7000   1.1854\n","36.   7.6724   8.9000   1.2276\n","37.  18.4012  22.1000   3.6988\n","38.   5.8405  12.1000   6.2595\n","39.  10.3142  10.1000   0.2142\n","40.   5.1928   3.3000   1.8928\n","41.   8.4446   8.5000   0.0554\n","42.   9.2603   8.1000   1.1603\n","43.  14.3628  14.5000   0.1372\n","44.   6.0427   4.9000   1.1427\n","45.   9.0159   8.5000   0.5159\n","46.  13.3882  12.1000   1.2882\n","47.  21.6748  23.7000   2.0252\n","48.   6.0160   3.7000   2.3160\n","49.   6.9638   9.3000   2.3362\n","50.   7.2906   8.1000   0.8094\n"]}],"source":["print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n","for i in range(50):\n","    diff = np.abs(y_val[i].item()-y_test[i].item())\n","    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"]},{"cell_type":"markdown","metadata":{"id":"1hU72l49GByW"},"source":["Como podemos ver, mientras algunas predicciones apenas difieren en unos céntimos, otras llegan a más de \\\\$15.00 de dferencia. Prueba a cambiar parámetros como el tamaño de lote, de test, el número de ciclos, la tasa de aprendizaje, etc. con el fin de conseguir un modelo mejor. "]},{"cell_type":"markdown","metadata":{"id":"tnWk8Vj4GByW"},"source":["## Guardando el modelo\n","Recordemos que podemos salvar un modelo entrenado como un fichero en disco de forma que podamos recuperarlo posterormente para realizar predicciones o continuar entrenandolo con más datos. \n","Habitualmente lo que suele hacerse es salvar las matrices de pesos y biases y no toda la definición. Podemos encontrar más información sobre el proceso de guardado y sus recomendaciones en  <a href='https://pytorch.org/tutorials/beginner/saving_loading_models.html'>https://pytorch.org/tutorials/beginner/saving_loading_models.html</a>"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":224,"status":"ok","timestamp":1673697033172,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"BLRKEkTxGByW"},"outputs":[],"source":["# Aseguramos que lo guardao SOLO depués de haberlo entrenado!\n","if len(losses) == epochs:\n","    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n","else:\n","    print('Model has not been trained. Consider loading a trained model instead.')"]},{"cell_type":"markdown","metadata":{"id":"kJlp6pILGByW"},"source":["## Cargando el modelo (empezando de cero)\n","Ahora podemos cargar el fichero con pesos y biases de nuestro modelo guardado. \n","Si acabamos de iniciar el Notebook, tendremos que lanzar las funciones de importación de módulos y sobretodo, las definiciones de funciones y clases. \n","\n","Para ilustrar esto reinicia  el Kernel antes de continuar. "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":5305,"status":"ok","timestamp":1673697075027,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"bXr-OLYwGByX"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","\n","def haversine_distance(df, lat1, long1, lat2, long2):\n","    r = 6371\n","    phi1 = np.radians(df[lat1])\n","    phi2 = np.radians(df[lat2])\n","    delta_phi = np.radians(df[lat2]-df[lat1])\n","    delta_lambda = np.radians(df[long2]-df[long1])\n","    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n","    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n","    return r * c\n","\n","class TabularModel(nn.Module):\n","    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n","        super().__init__()\n","        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n","        self.emb_drop = nn.Dropout(p)\n","        self.bn_cont = nn.BatchNorm1d(n_cont)\n","        layerlist = []\n","        n_emb = sum((nf for ni,nf in emb_szs))\n","        n_in = n_emb + n_cont\n","        for i in layers:\n","            layerlist.append(nn.Linear(n_in,i)) \n","            layerlist.append(nn.ReLU(inplace=True))\n","            layerlist.append(nn.BatchNorm1d(i))\n","            layerlist.append(nn.Dropout(p))\n","            n_in = i\n","        layerlist.append(nn.Linear(layers[-1],out_sz))\n","        self.layers = nn.Sequential(*layerlist)\n","    def forward(self, x_cat, x_cont):\n","        embeddings = []\n","        for i,e in enumerate(self.embeds):\n","            embeddings.append(e(x_cat[:,i]))\n","        x = torch.cat(embeddings, 1)\n","        x = self.emb_drop(x)\n","        x_cont = self.bn_cont(x_cont)\n","        x = torch.cat([x, x_cont], 1)\n","        return self.layers(x)"]},{"cell_type":"markdown","metadata":{"id":"NA4BslvHGByX"},"source":["Hemos definido las importaciones, funciones y clases. Ahora, antes de cargar los valores salvados, tenemos que instanciar nuestro modelo TabularModel con los mismos parámetros que antes (tamaños de embedding, número de columnas continuas, tamaño de salida, tamaño de capas y factor de dropout). "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":229,"status":"ok","timestamp":1673697082603,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"Z6HLIOnwGByX"},"outputs":[],"source":["emb_szs = [(24, 12), (2, 1), (7, 4)]\n","model2 = TabularModel(emb_szs, 6, 1, [10,100], p=0.4)"]},{"cell_type":"markdown","metadata":{"id":"BkACG4oPGByX"},"source":["Una vez cargado el modelo, cargar los valores ajustados es sencillo:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1673697088788,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"pBnuhNPcGByY","outputId":"280a6051-52d8-4c9e-c627-c7b642e5e200"},"outputs":[{"data":{"text/plain":["TabularModel(\n","  (embeds): ModuleList(\n","    (0): Embedding(24, 12)\n","    (1): Embedding(2, 1)\n","    (2): Embedding(7, 4)\n","  )\n","  (emb_drop): Dropout(p=0.4, inplace=False)\n","  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layers): Sequential(\n","    (0): Linear(in_features=23, out_features=10, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Linear(in_features=10, out_features=100, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): Dropout(p=0.4, inplace=False)\n","    (8): Linear(in_features=100, out_features=1, bias=True)\n","  )\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["model2.load_state_dict(torch.load('/content/TaxiFareRegrModel.pt'));\n","model2.eval() # No olvides realizar este paso"]},{"cell_type":"markdown","metadata":{"id":"KcyMaXBYGByY"},"source":["\n","Ahora podemos definir una función que solicite los datos de entrada al usuario , realice todos los pasos de preprocesado definidos al principio del Notebook y los pase al modelo entrenado con el fin de obtener una predicción concreta. "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":200,"status":"ok","timestamp":1673697111153,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"9DjDv2VoGByY"},"outputs":[],"source":["def test_data(mdl): # nombre del modelo que hemos instanciado\n","    # Nuevos datos:\n","    plat = float(input('Latitud de recogida: '))\n","    plong = float(input('Longitud de recogida: '))\n","    dlat = float(input('Latitud de entrega:  '))\n","    dlong = float(input('Longitud de entrega: '))\n","    psngr = int(input('Número de pasajeros '))\n","    dt = input('Especifica la fecha y hora en formato YYYY-MM-DD HH:MM:SS     ')\n","    \n","    # Preprocesado de lso datos:\n","    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n","         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n","    dfx = pd.DataFrame(dfx_dict, index=[0])\n","    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n","                                        'dropoff_latitude', 'dropoff_longitude')\n","    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n","    \n","    # Recodificamos las categoricas:\n","    dfx['Hour'] = dfx['EDTdate'].dt.hour\n","    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n","    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n","    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n","                                            [0,1,2,3,4,5,6]).astype('int64')\n","    # Creamos y concatenamos tensores\n","    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n","    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n","                 'dropoff_longitude', 'passenger_count', 'dist_km']\n","    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n","    xcats = torch.tensor(xcats, dtype=torch.int64)\n","    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n","    xconts = torch.tensor(xconts, dtype=torch.float)\n","    \n","    # Pasamos los nuevos datos al modelo. Sin backpropagacion\n","    with torch.no_grad():\n","        z = mdl(xcats, xconts)\n","    print(f'\\nLa distancia estimada es {dfx.iloc[0][\"dist_km\"]:.2f}km')\n","    print(f'\\nLa cantidad resultante es ${z.item():.2f}')\n","    return dfx"]},{"cell_type":"markdown","metadata":{"id":"9EvAoEKYGByZ"},"source":["## Introduciendo nuevos datos a través del modelo\n","\n","Como referencia, estos son los valores máximos y mínimos de las variables solicitadas:\n","<table style=\"display: inline-block\">\n","<tr><th>Column</th><th>Mínimo</th><th>Máximo</th></tr>\n","<tr><td>pickup_latitude</td><td>40</td><td>41</td></tr>\n","<tr><td>pickup_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n","<tr><td>dropoff_latitude</td><td>40</td><td>41</td></tr>\n","<tr><td>dropoff_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n","<tr><td>passenger_count</td><td>1</td><td>5</td></tr>\n","<tr><td>EDTdate</td><td>2010-04-11 00:00:00</td><td>2010-04-24 23:59:42</td></tr>"]},{"cell_type":"markdown","metadata":{"id":"-RIcbndgGByZ"},"source":["<strong>ATENCION!</strong> La distancia entre un grado de latitud (40 a 41) es 111km y en un grado de longitud (-73 a -74) is 85km. El viaje más largo en el dataset muestra una diferencia de solo 0.243 grados lat. y  0.284 de long. La diferencia media para ambos está en torno a 0.02. Para obtener una buena predicción hay que emplear valores cercanos. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59332,"status":"ok","timestamp":1673697187607,"user":{"displayName":"Juanjo Garces","userId":"15357993443425315544"},"user_tz":-60},"id":"Wcp0_BvlGByZ","outputId":"d6b3d374-4275-4660-fe79-679ff0d3a3b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Latitud de recogida: 40.1\n","Longitud de recogida: -73.5\n","Latitud de entrega:  40.3\n","Longitud de entrega: -73.8\n","Número de pasajeros 3\n","Especifica la fecha y hora en formato YYYY-MM-DD HH:MM:SS     2010-04-15 21:00:00\n","\n","La distancia estimada es 33.82km\n","\n","La cantidad resultante es $39.45\n"]}],"source":["z = test_data(model2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXe9J2mHtz2n"},"outputs":[],"source":["print(z)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBq0akVls6Ej"},"outputs":[],"source":["print(z['dist_km'])"]},{"cell_type":"markdown","metadata":{"id":"n2QOf-HEltUP"},"source":["## Fin del Notebook"]},{"cell_type":"markdown","metadata":{"id":"BZDr1zYmBkRV"},"source":["Referencias y modelos empleados para el Notebook: \n","\n","*   Documentación de [Pytorch](https://pytorch.org/docs/stable/index.html) \n","*   [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi\n","*   [FastAI](https://www.fast.ai/) development notebooks by Jeremy Howard.\n","*   Documentación y cursos en [Pierian Data](https://www.pieriandata.com/)\n","*   Tutoriales y notebooks del curso \"Deep Learning with Pytorch: Zero to GANs\" de [Aakash N S](https://jovian.ai/aakashns)\n","* [A visual proof that neural networks can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html), también conocido como Teorema de Aproximación Universal\n","* [But what *is* a neural network?](https://www.youtube.com/watch?v=aircAruvnKk) - Una introducción muy intuitiva a lo que son las redes neuronales y lo que implican las capas ocultas."]}],"metadata":{"colab":{"collapsed_sections":["n2QOf-HEltUP"],"provenance":[{"file_id":"1JSTUoVgg74IMjfsMOBubajfTIvBWj7VI","timestamp":1609881644021}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
