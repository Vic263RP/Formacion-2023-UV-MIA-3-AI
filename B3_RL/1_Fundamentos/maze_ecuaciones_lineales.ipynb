{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo del laberinto. Función de valor de una política (Evaluación de políticas) con ecuaciones lineales.\n",
    "\n",
    "Vamos a revisar esta implementación del ejercicio del laberinto que hemos visto en las diapositivas y que procede del libro de Sutton & Barto, en la que resolveremos el problema mediante el sistema de ecuaciones lineales que se plantea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Copyright (C)                                                       #\n",
    "# 2016-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
    "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
    "# Permission given to modify the code as long as you keep this        #\n",
    "# declaration at the top                                              #\n",
    "#######################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Definimos las estructuras de datos:  \n",
    " * Definimos las coordenadas de las posiciones especiales A, B, A', B'. \n",
    "   Ten en cuenta que los índices comienzan por 0 en python\n",
    " * Definimos  la variable DISCOUNT que es nuestra Gamma de teoria a un valor 0.9\n",
    " * La variable WORL_SIZE nos define un tablero o matriz de 5x5\n",
    " * El vector Actions define con dos códigos el cambio de índices en el tablero al moverse \n",
    "   ejemplo: estoy en [2,2], elijo la accion 'left', con  lo que sumo [2,2] + [0,-1] = [2,1] y estoy \n",
    "   una posición a la izquierda\n",
    " * La constante ACTION_PROB es la probabilidad de cada acción\n",
    " \n",
    "    -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.table import Table\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# WORLD_SIZE = 5\n",
    "# A_POS = [0, 1]\n",
    "# A_PRIME_POS = [4, 1]\n",
    "# B_POS = [0, 3]\n",
    "# B_PRIME_POS = [2, 3]\n",
    "# DISCOUNT = 0.9\n",
    "\n",
    "# # left, up, right, down\n",
    "# ACTIONS = [np.array([0, -1]),\n",
    "#            np.array([-1, 0]),\n",
    "#            np.array([0, 1]),\n",
    "#            np.array([1, 0])]\n",
    "# ACTIONS_FIGS=[ '←', '↑', '→', '↓']\n",
    "\n",
    "\n",
    "# ACTION_PROB = 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función 'step' implementa el paso elemental s_t,a_t,r_{t+1},s_{t+1},a_{t+1}\n",
    "- Si el estado actual es 'A' o 'B', salto a los puntos 'A'' o 'B'' y devuelvo la recompensa +10 ó +5 \n",
    "- Sino, hago el movimiento, sumándole al estado la acción (como hemos explicado antes) y compruebo si me he salido fuera del tablero.\n",
    "    - Si he salido, devuelvo -1 y vuelvo al estado anterior\n",
    "    - Si no he salido, devuelvo 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, action):\n",
    "    if state == A_POS:\n",
    "        return A_PRIME_POS, 10\n",
    "    if state == B_POS:\n",
    "        return B_PRIME_POS, 5\n",
    "\n",
    "    next_state = (np.array(state) + action).tolist()\n",
    "    x, y = next_state\n",
    "    if x < 0 or x >= WORLD_SIZE or y < 0 or y >= WORLD_SIZE:\n",
    "        reward = -1.0\n",
    "        next_state = state\n",
    "    else:\n",
    "        reward = 0\n",
    "    return next_state, reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dos funciones (celdas de código) siguientes no tienen interés algorítmico. Son para dibujar la imagen de los resultados del tablero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(image):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_axis_off()\n",
    "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
    "\n",
    "    nrows, ncols = image.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "\n",
    "    # Add cells\n",
    "    for (i, j), val in np.ndenumerate(image):\n",
    "\n",
    "        # add state labels\n",
    "        if [i, j] == A_POS:\n",
    "            val = str(val) + \" (A)\"\n",
    "        if [i, j] == A_PRIME_POS:\n",
    "            val = str(val) + \" (A')\"\n",
    "        if [i, j] == B_POS:\n",
    "            val = str(val) + \" (B)\"\n",
    "        if [i, j] == B_PRIME_POS:\n",
    "            val = str(val) + \" (B')\"\n",
    "        \n",
    "        tb.add_cell(i, j, width, height, text=val,\n",
    "                    loc='center', facecolor='white')\n",
    "        \n",
    "\n",
    "    # Row and column labels...\n",
    "    for i in range(len(image)):\n",
    "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
    "                    edgecolor='none', facecolor='none')\n",
    "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
    "                    edgecolor='none', facecolor='none')\n",
    "\n",
    "    ax.add_table(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_policy(optimal_values):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_axis_off()\n",
    "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
    "\n",
    "    nrows, ncols = optimal_values.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "\n",
    "    # Add cells\n",
    "    for (i, j), val in np.ndenumerate(optimal_values):\n",
    "        next_vals=[]\n",
    "        for action in ACTIONS:\n",
    "            next_state, _ = step([i, j], action)\n",
    "            next_vals.append(optimal_values[next_state[0],next_state[1]])\n",
    "\n",
    "        best_actions=np.where(next_vals == np.max(next_vals))[0]\n",
    "        val=''\n",
    "        for ba in best_actions:\n",
    "            val+=ACTIONS_FIGS[ba]\n",
    "        \n",
    "        # add state labels\n",
    "        if [i, j] == A_POS:\n",
    "            val = str(val) + \" (A)\"\n",
    "        if [i, j] == A_PRIME_POS:\n",
    "            val = str(val) + \" (A')\"\n",
    "        if [i, j] == B_POS:\n",
    "            val = str(val) + \" (B)\"\n",
    "        if [i, j] == B_PRIME_POS:\n",
    "            val = str(val) + \" (B')\"\n",
    "        \n",
    "        tb.add_cell(i, j, width, height, text=val,\n",
    "                loc='center', facecolor='white')\n",
    "\n",
    "    # Row and column labels...\n",
    "    for i in range(len(optimal_values)):\n",
    "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
    "                    edgecolor='none', facecolor='none')\n",
    "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
    "                   edgecolor='none', facecolor='none')\n",
    "\n",
    "    ax.add_table(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolución de las ecuaciones\n",
    "\n",
    "La función figure_3_2_linear_system() implementa el cálculo analítico mediante resolución del sistema de ecuaciones lineales.\n",
    "Devuelve dos imágenes: una con la función de valor y otra con la política encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def figure_3_2_linear_system():\n",
    "#     '''\n",
    "#     Here we solve the linear system of equations to find the exact solution.\n",
    "#     We do this by filling the coefficients for each of the states with their \n",
    "#     respective right side constant.\n",
    "#     '''\n",
    "#     A = -1 * np.eye(WORLD_SIZE * WORLD_SIZE)\n",
    "#     b = np.zeros(WORLD_SIZE * WORLD_SIZE)\n",
    "    \n",
    "#     #AQUI PREPARA LAS MATRICES R y P de teoria\n",
    "#     #EN LA FORMA (discount*P-I)V = -R\n",
    "#     #donde A = (discount*P-I), b = -R\n",
    "#     for i in range(WORLD_SIZE):\n",
    "#         for j in range(WORLD_SIZE):\n",
    "#             s = [i, j]  # current state\n",
    "#             index_s = np.ravel_multi_index(s, (WORLD_SIZE, WORLD_SIZE))\n",
    "#             for a in ACTIONS:\n",
    "#                 s_, r = step(s, a)\n",
    "#                 index_s_ = np.ravel_multi_index(s_, (WORLD_SIZE, WORLD_SIZE))\n",
    "\n",
    "#                 #AQUI MODIFICACION PARA EL EJERCICIO 1\n",
    "#                 A[index_s, index_s_] += ACTION_PROB * DISCOUNT\n",
    "                \n",
    "                \n",
    "#                 b[index_s] -= ACTION_PROB * r\n",
    "                \n",
    "\n",
    "#     x = np.linalg.solve(A, b)\n",
    "    \n",
    "#     draw_policy(np.round(x.reshape(WORLD_SIZE, WORLD_SIZE), decimals=2))\n",
    "#     plt.savefig('figure_policy_linear.png')\n",
    "    \n",
    "#     draw_image(np.round(x.reshape(WORLD_SIZE, WORLD_SIZE), decimals=2))\n",
    "#     plt.savefig('figure_3_2_linear_system.png')\n",
    "    \n",
    "    \n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecuta la función principal para hallar la función de valor V asociada a la política. Como resultado, se generan dos archivos *.png en el directorio de ejecución con la solución para cada estado de la rejilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == '__main__':\n",
    "#     figure_3_2_linear_system()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: \n",
    "Modifica ahora la política para hallar la función de valor correspondiente a otra política.\n",
    "Vamos a considerar la política determinista: P(N)=0.2 P(S)= 0.3, P(E) = 0.4 P(O) = 0.1\n",
    "Modifica el código anterior y calcula la nueva función de valor asociada a esta política.\n",
    "La solucion es: <img src=\"sol2.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORLD_SIZE = 5\n",
    "A_POS = [0, 1]\n",
    "A_PRIME_POS = [4, 1]\n",
    "B_POS = [0, 3]\n",
    "B_PRIME_POS = [2, 3]\n",
    "DISCOUNT = 0.9\n",
    "\n",
    "# left, up, right, down\n",
    "ACTIONS = [np.array([0, -1]),\n",
    "           np.array([-1, 0]),\n",
    "           np.array([0, 1]),\n",
    "           np.array([1, 0])]\n",
    "ACTIONS_FIGS=[ '←', '↑', '→', '↓']\n",
    "\n",
    "\n",
    "ACTION_PROB = [0.4, 0.2, 0.1, 0.3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_3_2_linear_system():\n",
    "    '''\n",
    "    Here we solve the linear system of equations to find the exact solution.\n",
    "    We do this by filling the coefficients for each of the states with their \n",
    "    respective right side constant.\n",
    "    '''\n",
    "    A = -1 * np.eye(WORLD_SIZE * WORLD_SIZE)\n",
    "    b = np.zeros(WORLD_SIZE * WORLD_SIZE)\n",
    "    \n",
    "    #AQUI PREPARA LAS MATRICES R y P de teoria\n",
    "    #EN LA FORMA (discount*P-I)V = -R\n",
    "    #donde A = (discount*P-I), b = -R\n",
    "    for i in range(WORLD_SIZE):\n",
    "        for j in range(WORLD_SIZE):\n",
    "            s = [i, j]  # current state\n",
    "            index_s = np.ravel_multi_index(s, (WORLD_SIZE, WORLD_SIZE))\n",
    "            for a in range(len(ACTIONS)):\n",
    "                s_, r = step(s, ACTIONS[a])\n",
    "                index_s_ = np.ravel_multi_index(s_, (WORLD_SIZE, WORLD_SIZE))\n",
    "\n",
    "                #AQUI MODIFICACION PARA EL EJERCICIO 1\n",
    "                A[index_s, index_s_] += ACTION_PROB[a] * DISCOUNT\n",
    "                \n",
    "                \n",
    "                b[index_s] -= ACTION_PROB[a] * r\n",
    "                \n",
    "\n",
    "    x = np.linalg.solve(A, b)\n",
    "    \n",
    "    draw_policy(np.round(x.reshape(WORLD_SIZE, WORLD_SIZE), decimals=2))\n",
    "    plt.savefig('figure_policy_linear.png')\n",
    "    \n",
    "    draw_image(np.round(x.reshape(WORLD_SIZE, WORLD_SIZE), decimals=2))\n",
    "    plt.savefig('figure_3_2_linear_system.png')\n",
    "    \n",
    "    \n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    figure_3_2_linear_system()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
